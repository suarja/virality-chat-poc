#!/usr/bin/env python3
"""
Comprehensive Feature Extractor - ImplÃ©mentation complÃ¨te du feature engineering crÃ©atif
BasÃ© sur la recherche scientifique, l'innovation et les donnÃ©es disponibles.
"""

import logging
import json
import numpy as np
import pandas as pd
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any, Union
from datetime import datetime, timedelta
from dataclasses import dataclass
from enum import Enum

logger = logging.getLogger(__name__)


class FeatureCategory(Enum):
    """CatÃ©gories de features."""
    METADATA = "metadata"
    VISUAL = "visual"
    AUDIO = "audio"
    TEMPORAL = "temporal"
    PSYCHOLOGICAL = "psychological"
    CULTURAL = "cultural"
    CREATIVITY = "creativity"
    PERFORMANCE = "performance"


@dataclass
class FeatureDefinition:
    """DÃ©finition d'une feature avec mÃ©tadonnÃ©es."""
    name: str
    category: FeatureCategory
    data_type: str
    description: str
    extraction_method: str
    complexity: str  # 'easy', 'moderate', 'complex'
    research_based: bool
    actionable: bool


class ComprehensiveFeatureExtractor:
    """
    Extracteur de features complet pour TikTok virality prediction.
    Combine features existantes, recherche scientifique et innovation crÃ©ative.
    """

    def __init__(self):
        """Initialise l'extracteur avec toutes les dÃ©finitions de features."""
        self.feature_definitions = self._define_all_features()
        self.extraction_stats = {
            'features_extracted': 0,
            'extraction_time': 0,
            'errors': []
        }

    def _define_all_features(self) -> Dict[str, FeatureDefinition]:
        """DÃ©finit toutes les features avec leurs mÃ©tadonnÃ©es."""

        features = {
            # === PHASE 1: FOUNDATION FEATURES ===

            # MÃ©tadonnÃ©es amÃ©liorÃ©es
            'video_duration_optimized': FeatureDefinition(
                name='video_duration_optimized',
                category=FeatureCategory.METADATA,
                data_type='float',
                description='DurÃ©e optimisÃ©e pour la plateforme (15-60s optimal)',
                extraction_method='duration_analysis',
                complexity='easy',
                research_based=True,
                actionable=True
            ),

            'hashtag_effectiveness_score': FeatureDefinition(
                name='hashtag_effectiveness_score',
                category=FeatureCategory.METADATA,
                data_type='float',
                description='Score d\'efficacitÃ© des hashtags (0-1)',
                extraction_method='hashtag_analysis',
                complexity='moderate',
                research_based=True,
                actionable=True
            ),

            'music_trend_alignment': FeatureDefinition(
                name='music_trend_alignment',
                category=FeatureCategory.AUDIO,
                data_type='float',
                description='Alignement avec les tendances musicales (0-1)',
                extraction_method='music_trend_analysis',
                complexity='moderate',
                research_based=True,
                actionable=True
            ),

            'publish_timing_score': FeatureDefinition(
                name='publish_timing_score',
                category=FeatureCategory.TEMPORAL,
                data_type='float',
                description='Score de timing de publication (0-1)',
                extraction_method='temporal_analysis',
                complexity='easy',
                research_based=True,
                actionable=True
            ),

            # Visuelles granulaires
            'human_count': FeatureDefinition(
                name='human_count',
                category=FeatureCategory.VISUAL,
                data_type='int',
                description='Nombre de personnes dans la vidÃ©o',
                extraction_method='gemini_vision',
                complexity='moderate',
                research_based=True,
                actionable=True
            ),

            'eye_contact_with_camera': FeatureDefinition(
                name='eye_contact_with_camera',
                category=FeatureCategory.VISUAL,
                data_type='bool',
                description='Contact visuel avec la camÃ©ra',
                extraction_method='gemini_vision',
                complexity='moderate',
                research_based=True,
                actionable=True
            ),

            'shot_type': FeatureDefinition(
                name='shot_type',
                category=FeatureCategory.VISUAL,
                data_type='str',
                description='Type de plan (close-up, medium, wide, extreme close-up)',
                extraction_method='gemini_vision',
                complexity='moderate',
                research_based=True,
                actionable=True
            ),

            'color_vibrancy_score': FeatureDefinition(
                name='color_vibrancy_score',
                category=FeatureCategory.VISUAL,
                data_type='float',
                description='Score de saturation des couleurs (0-1)',
                extraction_method='gemini_vision',
                complexity='moderate',
                research_based=True,
                actionable=True
            ),

            # Temporelles avancÃ©es
            'seasonal_timing_score': FeatureDefinition(
                name='seasonal_timing_score',
                category=FeatureCategory.TEMPORAL,
                data_type='float',
                description='Score de timing saisonnier (0-1)',
                extraction_method='seasonal_analysis',
                complexity='easy',
                research_based=True,
                actionable=True
            ),

            'trending_moment_alignment': FeatureDefinition(
                name='trending_moment_alignment',
                category=FeatureCategory.TEMPORAL,
                data_type='float',
                description='Alignement avec les moments tendance (0-1)',
                extraction_method='trend_analysis',
                complexity='moderate',
                research_based=True,
                actionable=True
            ),

            'competition_level': FeatureDefinition(
                name='competition_level',
                category=FeatureCategory.TEMPORAL,
                data_type='float',
                description='Niveau de concurrence au moment de publication (0-1)',
                extraction_method='competition_analysis',
                complexity='complex',
                research_based=False,
                actionable=True
            ),

            # === PHASE 2: ADVANCED FEATURES ===

            # Audio avancÃ©
            'music_energy': FeatureDefinition(
                name='music_energy',
                category=FeatureCategory.AUDIO,
                data_type='float',
                description='Ã‰nergie musicale (0-1)',
                extraction_method='audio_analysis',
                complexity='complex',
                research_based=True,
                actionable=True
            ),

            'audio_visual_sync_score': FeatureDefinition(
                name='audio_visual_sync_score',
                category=FeatureCategory.AUDIO,
                data_type='float',
                description='Synchronisation audio-visuelle (0-1)',
                extraction_method='sync_analysis',
                complexity='complex',
                research_based=True,
                actionable=True
            ),

            'voice_emotion': FeatureDefinition(
                name='voice_emotion',
                category=FeatureCategory.AUDIO,
                data_type='str',
                description='Ã‰motion dÃ©tectÃ©e dans la voix',
                extraction_method='voice_analysis',
                complexity='complex',
                research_based=True,
                actionable=True
            ),

            # Composition avancÃ©e
            'rule_of_thirds_score': FeatureDefinition(
                name='rule_of_thirds_score',
                category=FeatureCategory.VISUAL,
                data_type='float',
                description='Respect de la rÃ¨gle des tiers (0-1)',
                extraction_method='composition_analysis',
                complexity='moderate',
                research_based=True,
                actionable=True
            ),

            'depth_of_field_type': FeatureDefinition(
                name='depth_of_field_type',
                category=FeatureCategory.VISUAL,
                data_type='str',
                description='Type de profondeur de champ',
                extraction_method='gemini_vision',
                complexity='moderate',
                research_based=True,
                actionable=True
            ),

            'color_palette_type': FeatureDefinition(
                name='color_palette_type',
                category=FeatureCategory.VISUAL,
                data_type='str',
                description='Type de palette de couleurs',
                extraction_method='color_analysis',
                complexity='moderate',
                research_based=True,
                actionable=True
            ),

            # Psychologique
            'attention_grab_strength': FeatureDefinition(
                name='attention_grab_strength',
                category=FeatureCategory.PSYCHOLOGICAL,
                data_type='float',
                description='Force d\'accroche de l\'attention (0-1)',
                extraction_method='attention_analysis',
                complexity='complex',
                research_based=True,
                actionable=True
            ),

            'emotional_hook_strength': FeatureDefinition(
                name='emotional_hook_strength',
                category=FeatureCategory.PSYCHOLOGICAL,
                data_type='float',
                description='Force du hook Ã©motionnel (0-1)',
                extraction_method='emotional_analysis',
                complexity='complex',
                research_based=True,
                actionable=True
            ),

            'relatability_score': FeatureDefinition(
                name='relatability_score',
                category=FeatureCategory.PSYCHOLOGICAL,
                data_type='float',
                description='Score de relatabilitÃ© (0-1)',
                extraction_method='relatability_analysis',
                complexity='complex',
                research_based=True,
                actionable=True
            ),

            # CrÃ©ativitÃ©
            'originality_score': FeatureDefinition(
                name='originality_score',
                category=FeatureCategory.CREATIVITY,
                data_type='float',
                description='Score d\'originalitÃ© (0-1)',
                extraction_method='originality_analysis',
                complexity='complex',
                research_based=False,
                actionable=True
            ),

            'creative_technique_count': FeatureDefinition(
                name='creative_technique_count',
                category=FeatureCategory.CREATIVITY,
                data_type='int',
                description='Nombre de techniques crÃ©atives utilisÃ©es',
                extraction_method='creativity_analysis',
                complexity='moderate',
                research_based=False,
                actionable=True
            ),

            'story_structure_type': FeatureDefinition(
                name='story_structure_type',
                category=FeatureCategory.CREATIVITY,
                data_type='str',
                description='Type de structure narrative',
                extraction_method='storytelling_analysis',
                complexity='moderate',
                research_based=True,
                actionable=True
            ),

            # === PHASE 3: INNOVATION FEATURES ===

            # Contexte culturel
            'cultural_relevance_score': FeatureDefinition(
                name='cultural_relevance_score',
                category=FeatureCategory.CULTURAL,
                data_type='float',
                description='Pertinence culturelle (0-1)',
                extraction_method='cultural_analysis',
                complexity='complex',
                research_based=False,
                actionable=True
            ),

            'generational_appeal': FeatureDefinition(
                name='generational_appeal',
                category=FeatureCategory.CULTURAL,
                data_type='str',
                description='Appel gÃ©nÃ©rationnel',
                extraction_method='generational_analysis',
                complexity='complex',
                research_based=False,
                actionable=True
            ),

            'social_issue_relevance': FeatureDefinition(
                name='social_issue_relevance',
                category=FeatureCategory.CULTURAL,
                data_type='float',
                description='Pertinence des enjeux sociaux (0-1)',
                extraction_method='social_analysis',
                complexity='complex',
                research_based=False,
                actionable=True
            ),

            # ViralitÃ© potentielle
            'shareability_score': FeatureDefinition(
                name='shareability_score',
                category=FeatureCategory.PERFORMANCE,
                data_type='float',
                description='Score de partage (0-1)',
                extraction_method='shareability_analysis',
                complexity='complex',
                research_based=False,
                actionable=True
            ),

            'meme_potential': FeatureDefinition(
                name='meme_potential',
                category=FeatureCategory.PERFORMANCE,
                data_type='float',
                description='Potentiel meme (0-1)',
                extraction_method='meme_analysis',
                complexity='complex',
                research_based=False,
                actionable=True
            ),

            'challenge_potential': FeatureDefinition(
                name='challenge_potential',
                category=FeatureCategory.PERFORMANCE,
                data_type='float',
                description='Potentiel challenge (0-1)',
                extraction_method='challenge_analysis',
                complexity='moderate',
                research_based=False,
                actionable=True
            ),

            # Performance
            'completion_rate_prediction': FeatureDefinition(
                name='completion_rate_prediction',
                category=FeatureCategory.PERFORMANCE,
                data_type='float',
                description='PrÃ©diction du taux de completion (0-1)',
                extraction_method='completion_analysis',
                complexity='complex',
                research_based=True,
                actionable=True
            ),

            'virality_velocity': FeatureDefinition(
                name='virality_velocity',
                category=FeatureCategory.PERFORMANCE,
                data_type='float',
                description='VÃ©locitÃ© de viralitÃ© (0-1)',
                extraction_method='velocity_analysis',
                complexity='complex',
                research_based=False,
                actionable=True
            ),

            'user_experience_score': FeatureDefinition(
                name='user_experience_score',
                category=FeatureCategory.PERFORMANCE,
                data_type='float',
                description='Score d\'expÃ©rience utilisateur (0-1)',
                extraction_method='ux_analysis',
                complexity='moderate',
                research_based=False,
                actionable=True
            ),
        }

        return features

    def extract_phase1_features(self, video_data: Dict, gemini_analysis: Optional[Dict] = None) -> Dict:
        """
        Extrait les features de Phase 1 (Foundation).
        """
        features = {}

        try:
            # MÃ©tadonnÃ©es amÃ©liorÃ©es
            features.update(self._extract_enhanced_metadata(video_data))

            # Visuelles granulaires (si Gemini disponible)
            if gemini_analysis:
                features.update(
                    self._extract_granular_visual_features(gemini_analysis))

            # Temporelles avancÃ©es
            features.update(
                self._extract_advanced_temporal_features(video_data))

            self.extraction_stats['features_extracted'] += len(features)

        except Exception as e:
            logger.error(f"Error extracting Phase 1 features: {e}")
            self.extraction_stats['errors'].append(f"Phase 1: {str(e)}")

        return features

    def extract_phase2_features(self, video_data: Dict, gemini_analysis: Optional[Dict] = None) -> Dict:
        """
        Extrait les features de Phase 2 (Advanced).
        """
        features = {}

        try:
            # Audio avancÃ©
            features.update(self._extract_advanced_audio_features(
                video_data, gemini_analysis))

            # Composition avancÃ©e
            if gemini_analysis:
                features.update(
                    self._extract_advanced_composition_features(gemini_analysis))

            # Psychologique
            features.update(self._extract_psychological_features(
                video_data, gemini_analysis))

            # CrÃ©ativitÃ©
            features.update(self._extract_creativity_features(
                video_data, gemini_analysis))

            self.extraction_stats['features_extracted'] += len(features)

        except Exception as e:
            logger.error(f"Error extracting Phase 2 features: {e}")
            self.extraction_stats['errors'].append(f"Phase 2: {str(e)}")

        return features

    def extract_phase3_features(self, video_data: Dict, gemini_analysis: Optional[Dict] = None) -> Dict:
        """
        Extrait les features de Phase 3 (Innovation).
        """
        features = {}

        try:
            # Contexte culturel
            features.update(
                self._extract_cultural_context_features(video_data))

            # ViralitÃ© potentielle
            features.update(self._extract_virality_potential_features(
                video_data, gemini_analysis))

            # Performance
            features.update(self._extract_performance_features(video_data))

            self.extraction_stats['features_extracted'] += len(features)

        except Exception as e:
            logger.error(f"Error extracting Phase 3 features: {e}")
            self.extraction_stats['errors'].append(f"Phase 3: {str(e)}")

        return features

    def _extract_enhanced_metadata(self, video_data: Dict) -> Dict:
        """Extrait les mÃ©tadonnÃ©es amÃ©liorÃ©es."""
        features = {}

        # DurÃ©e optimisÃ©e
        duration = video_data.get('duration', 0)
        if duration <= 15:
            features['video_duration_optimized'] = 0.8  # Optimal pour TikTok
        elif duration <= 30:
            features['video_duration_optimized'] = 1.0  # TrÃ¨s optimal
        elif duration <= 60:
            features['video_duration_optimized'] = 0.6  # Acceptable
        else:
            features['video_duration_optimized'] = 0.3  # Trop long

        # Score d'efficacitÃ© des hashtags
        hashtag_count = len(video_data.get('hashtags', []))
        if 3 <= hashtag_count <= 5:
            features['hashtag_effectiveness_score'] = 1.0  # Optimal
        elif 1 <= hashtag_count <= 7:
            features['hashtag_effectiveness_score'] = 0.7  # Acceptable
        else:
            features['hashtag_effectiveness_score'] = 0.3  # Non optimal

        # Alignement musique tendance (placeholder)
        # Ã€ implÃ©menter avec API musique
        features['music_trend_alignment'] = 0.5

        # Score de timing de publication
        post_time = pd.to_datetime(video_data.get('createTimeISO', ''))
        hour = post_time.hour

        if 19 <= hour <= 21:
            features['publish_timing_score'] = 1.0  # Heures de pointe
        elif 18 <= hour <= 22:
            features['publish_timing_score'] = 0.8  # Bon timing
        elif 9 <= hour <= 17:
            features['publish_timing_score'] = 0.6  # Heures de travail
        else:
            features['publish_timing_score'] = 0.4  # Heures creuses

        return features

    def _extract_granular_visual_features(self, gemini_analysis: Dict) -> Dict:
        """Extrait les features visuelles granulaires depuis Gemini."""
        features = {}

        visual_analysis = gemini_analysis.get('visual_analysis', {})

        # Nombre d'humains
        human_text = visual_analysis.get('human_presence', '')
        if 'multiple people' in human_text.lower():
            features['human_count'] = 3
        elif 'two people' in human_text.lower():
            features['human_count'] = 2
        elif 'person' in human_text.lower() or 'human' in human_text.lower():
            features['human_count'] = 1
        else:
            features['human_count'] = 0

        # Contact visuel
        features['eye_contact_with_camera'] = 'eye contact' in human_text.lower()

        # Type de plan
        shot_text = visual_analysis.get('shot_type', '')
        if 'close-up' in shot_text.lower():
            features['shot_type'] = 'close_up'
        elif 'medium' in shot_text.lower():
            features['shot_type'] = 'medium'
        elif 'wide' in shot_text.lower():
            features['shot_type'] = 'wide'
        else:
            features['shot_type'] = 'unknown'

        # Score de saturation des couleurs
        color_text = visual_analysis.get('color_analysis', '')
        if 'vibrant' in color_text.lower() or 'saturated' in color_text.lower():
            features['color_vibrancy_score'] = 0.8
        elif 'bright' in color_text.lower():
            features['color_vibrancy_score'] = 0.6
        elif 'muted' in color_text.lower() or 'dull' in color_text.lower():
            features['color_vibrancy_score'] = 0.3
        else:
            features['color_vibrancy_score'] = 0.5

        return features

    def _extract_advanced_temporal_features(self, video_data: Dict) -> Dict:
        """Extrait les features temporelles avancÃ©es."""
        features = {}

        post_time = pd.to_datetime(video_data.get('createTimeISO', ''))

        # Score de timing saisonnier
        month = post_time.month
        if month in [6, 7, 8]:  # Ã‰tÃ©
            features['seasonal_timing_score'] = 0.8
        elif month in [12, 1, 2]:  # Hiver
            features['seasonal_timing_score'] = 0.7
        else:
            features['seasonal_timing_score'] = 0.6

        # Alignement moment tendance (placeholder)
        # Ã€ implÃ©menter avec API tendances
        features['trending_moment_alignment'] = 0.5

        # Niveau de concurrence (placeholder)
        # Ã€ implÃ©menter avec analyse concurrentielle
        features['competition_level'] = 0.5

        return features

    def _extract_advanced_audio_features(self, video_data: Dict, gemini_analysis: Optional[Dict]) -> Dict:
        """Extrait les features audio avancÃ©es."""
        features = {}

        # Ã‰nergie musicale (placeholder)
        features['music_energy'] = 0.6  # Ã€ implÃ©menter avec analyse audio

        # Synchronisation audio-visuelle (placeholder)
        # Ã€ implÃ©menter avec analyse sync
        features['audio_visual_sync_score'] = 0.7

        # Ã‰motion vocale (placeholder)
        # Ã€ implÃ©menter avec analyse vocale
        features['voice_emotion'] = 'neutral'

        return features

    def _extract_advanced_composition_features(self, gemini_analysis: Dict) -> Dict:
        """Extrait les features de composition avancÃ©e."""
        features = {}

        visual_analysis = gemini_analysis.get('visual_analysis', {})

        # Score rÃ¨gle des tiers (placeholder)
        # Ã€ implÃ©menter avec analyse composition
        features['rule_of_thirds_score'] = 0.7

        # Type de profondeur de champ
        depth_text = visual_analysis.get('depth_analysis', '')
        if 'shallow' in depth_text.lower():
            features['depth_of_field_type'] = 'shallow'
        elif 'deep' in depth_text.lower():
            features['depth_of_field_type'] = 'deep'
        else:
            features['depth_of_field_type'] = 'medium'

        # Type de palette de couleurs (placeholder)
        # Ã€ implÃ©menter avec analyse couleur
        features['color_palette_type'] = 'complementary'

        return features

    def _extract_psychological_features(self, video_data: Dict, gemini_analysis: Optional[Dict]) -> Dict:
        """Extrait les features psychologiques."""
        features = {}

        # Force d'accroche (placeholder)
        # Ã€ implÃ©menter avec analyse attention
        features['attention_grab_strength'] = 0.6

        # Force du hook Ã©motionnel (placeholder)
        # Ã€ implÃ©menter avec analyse Ã©motionnelle
        features['emotional_hook_strength'] = 0.7

        # Score de relatabilitÃ© (placeholder)
        # Ã€ implÃ©menter avec analyse relatabilitÃ©
        features['relatability_score'] = 0.5

        return features

    def _extract_creativity_features(self, video_data: Dict, gemini_analysis: Optional[Dict]) -> Dict:
        """Extrait les features de crÃ©ativitÃ©."""
        features = {}

        # Score d'originalitÃ© (placeholder)
        # Ã€ implÃ©menter avec analyse originalitÃ©
        features['originality_score'] = 0.6

        # Nombre de techniques crÃ©atives (placeholder)
        # Ã€ implÃ©menter avec analyse crÃ©ativitÃ©
        features['creative_technique_count'] = 2

        # Type de structure narrative (placeholder)
        # Ã€ implÃ©menter avec analyse storytelling
        features['story_structure_type'] = 'linear'

        return features

    def _extract_cultural_context_features(self, video_data: Dict) -> Dict:
        """Extrait les features de contexte culturel."""
        features = {}

        # Pertinence culturelle (placeholder)
        # Ã€ implÃ©menter avec analyse culturelle
        features['cultural_relevance_score'] = 0.5

        # Appel gÃ©nÃ©rationnel (placeholder)
        # Ã€ implÃ©menter avec analyse gÃ©nÃ©rationnelle
        features['generational_appeal'] = 'Gen Z'

        # Pertinence des enjeux sociaux (placeholder)
        # Ã€ implÃ©menter avec analyse sociale
        features['social_issue_relevance'] = 0.3

        return features

    def _extract_virality_potential_features(self, video_data: Dict, gemini_analysis: Optional[Dict]) -> Dict:
        """Extrait les features de potentiel viral."""
        features = {}

        # Score de partage (placeholder)
        # Ã€ implÃ©menter avec analyse partage
        features['shareability_score'] = 0.6

        # Potentiel meme (placeholder)
        features['meme_potential'] = 0.4  # Ã€ implÃ©menter avec analyse meme

        # Potentiel challenge (placeholder)
        # Ã€ implÃ©menter avec analyse challenge
        features['challenge_potential'] = 0.5

        return features

    def _extract_performance_features(self, video_data: Dict) -> Dict:
        """Extrait les features de performance."""
        features = {}

        # PrÃ©diction taux de completion (placeholder)
        # Ã€ implÃ©menter avec modÃ¨le prÃ©dictif
        features['completion_rate_prediction'] = 0.7

        # VÃ©locitÃ© de viralitÃ© (placeholder)
        # Ã€ implÃ©menter avec analyse vÃ©locitÃ©
        features['virality_velocity'] = 0.5

        # Score d'expÃ©rience utilisateur (placeholder)
        # Ã€ implÃ©menter avec analyse UX
        features['user_experience_score'] = 0.6

        return features

    def extract_all_features(
        self,
        video_data: Dict,
        gemini_analysis: Optional[Dict] = None,
        phases: List[int] = [1, 2, 3]
    ) -> Dict:
        """
        Extrait toutes les features selon les phases spÃ©cifiÃ©es.

        Args:
            video_data: DonnÃ©es vidÃ©o TikTok
            gemini_analysis: Analyse Gemini (optionnel)
            phases: Phases Ã  extraire [1, 2, 3]

        Returns:
            Dictionnaire avec toutes les features extraites
        """
        start_time = datetime.now()
        all_features = {}

        try:
            # Phase 1: Foundation
            if 1 in phases:
                phase1_features = self.extract_phase1_features(
                    video_data, gemini_analysis)
                all_features.update(phase1_features)
                logger.info(
                    f"Extracted {len(phase1_features)} Phase 1 features")

            # Phase 2: Advanced
            if 2 in phases:
                phase2_features = self.extract_phase2_features(
                    video_data, gemini_analysis)
                all_features.update(phase2_features)
                logger.info(
                    f"Extracted {len(phase2_features)} Phase 2 features")

            # Phase 3: Innovation
            if 3 in phases:
                phase3_features = self.extract_phase3_features(
                    video_data, gemini_analysis)
                all_features.update(phase3_features)
                logger.info(
                    f"Extracted {len(phase3_features)} Phase 3 features")

            # Ajouter les mÃ©tadonnÃ©es de base
            all_features['video_id'] = video_data.get('id', '')
            all_features['extraction_timestamp'] = datetime.now().isoformat()

            self.extraction_stats['extraction_time'] = (
                datetime.now() - start_time).total_seconds()

        except Exception as e:
            logger.error(f"Error in comprehensive feature extraction: {e}")
            self.extraction_stats['errors'].append(f"Comprehensive: {str(e)}")

        return all_features

    def get_feature_summary(self) -> Dict:
        """Retourne un rÃ©sumÃ© des features extraites."""
        return {
            'total_features_defined': len(self.feature_definitions),
            'features_by_category': {
                category.value: len(
                    [f for f in self.feature_definitions.values() if f.category == category])
                for category in FeatureCategory
            },
            'features_by_complexity': {
                complexity: len(
                    [f for f in self.feature_definitions.values() if f.complexity == complexity])
                for complexity in ['easy', 'moderate', 'complex']
            },
            'research_based_features': len([f for f in self.feature_definitions.values() if f.research_based]),
            'actionable_features': len([f for f in self.feature_definitions.values() if f.actionable]),
            'extraction_stats': self.extraction_stats
        }


def main():
    """Fonction principale pour tester l'extracteur complet."""

    # CrÃ©er l'extracteur
    extractor = ComprehensiveFeatureExtractor()

    # Afficher le rÃ©sumÃ© des features
    summary = extractor.get_feature_summary()

    print("ğŸ¯ Comprehensive Feature Extractor - Summary")
    print("=" * 50)
    print(f"Total features defined: {summary['total_features_defined']}")
    print(f"Research-based features: {summary['research_based_features']}")
    print(f"Actionable features: {summary['actionable_features']}")

    print("\nğŸ“Š Features by Category:")
    for category, count in summary['features_by_category'].items():
        print(f"  â€¢ {category}: {count}")

    print("\nğŸ”§ Features by Complexity:")
    for complexity, count in summary['features_by_complexity'].items():
        print(f"  â€¢ {complexity}: {count}")

    print("\nğŸ“‹ Feature Definitions:")
    for name, feature in extractor.feature_definitions.items():
        print(f"  â€¢ {name}: {feature.description}")

    return extractor


if __name__ == "__main__":
    extractor = main()
