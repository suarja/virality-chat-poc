#!/usr/bin/env python3
"""
Script de test rapide pour le POC de virality prediction.
Teste le pipeline end-to-end avec un dataset minimal.
"""
import subprocess
import sys
from pathlib import Path
import logging


def setup_logging():
    """Setup logging configuration."""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )
    return logging.getLogger(__name__)


def run_command(command, description):
    """ExÃ©cute une commande et log le rÃ©sultat."""
    logger = logging.getLogger(__name__)
    logger.info(f"ğŸš€ {description}")
    logger.info(f"Commande: {command}")

    try:
        result = subprocess.run(command, shell=True,
                                capture_output=True, text=True)

        if result.returncode == 0:
            logger.info(f"âœ… {description} - SuccÃ¨s")
            if result.stdout:
                logger.info(f"Sortie: {result.stdout.strip()}")
        else:
            logger.error(f"âŒ {description} - Ã‰chec")
            logger.error(f"Erreur: {result.stderr.strip()}")
            return False

    except Exception as e:
        logger.error(f"âŒ {description} - Exception: {e}")
        return False

    return True


def test_poc_pipeline():
    """Teste le pipeline POC complet."""
    logger = logging.getLogger(__name__)

    print("\n" + "="*80)
    print("ğŸš€ TEST POC PIPELINE - VALIDATION RAPIDE")
    print("="*80)

    # Test 1: Pipeline de scraping et analyse
    logger.info("\nğŸ“‹ Test 1: Pipeline complet (scraping + Gemini + features)")

    pipeline_cmd = [
        "python3", "scripts/run_pipeline.py",
        "--dataset", "poc_test",
        "--batch-size", "1",
        "--videos-per-account", "5",
        "--max-total-videos", "10",
        "--feature-system", "modular",
        "--feature-set", "comprehensive"
    ]

    success = run_command(" ".join(pipeline_cmd), "Pipeline complet")

    if not success:
        logger.error("âŒ Le pipeline a Ã©chouÃ©. ArrÃªt du test.")
        return False

    # Test 2: AgrÃ©gation des features
    logger.info("\nğŸ“‹ Test 2: AgrÃ©gation des features")

    aggregate_cmd = [
        "python3", "scripts/aggregate_features.py",
        "--dataset-dir", "data/dataset_poc_test",
        "--feature-set", "comprehensive",
        "--show-stats"
    ]

    success = run_command(" ".join(aggregate_cmd), "AgrÃ©gation des features")

    if not success:
        logger.error("âŒ L'agrÃ©gation a Ã©chouÃ©.")
        return False

    # Test 3: VÃ©rification des fichiers gÃ©nÃ©rÃ©s
    logger.info("\nğŸ“‹ Test 3: VÃ©rification des fichiers gÃ©nÃ©rÃ©s")

    dataset_dir = Path("data/dataset_poc_test")
    features_dir = dataset_dir / "features"

    files_to_check = [
        features_dir / "aggregated_comprehensive.csv",
        dataset_dir / "gemini_analysis",
        dataset_dir / "batch_*.json"
    ]

    all_files_exist = True
    for file_pattern in files_to_check:
        if file_pattern.name == "batch_*.json":
            batch_files = list(dataset_dir.glob("batch_*.json"))
            if batch_files:
                logger.info(f"âœ… Fichiers batch trouvÃ©s: {len(batch_files)}")
            else:
                logger.error(f"âŒ Aucun fichier batch trouvÃ©")
                all_files_exist = False
        elif file_pattern.name == "gemini_analysis":
            if file_pattern.exists():
                analysis_dirs = list(file_pattern.iterdir())
                logger.info(
                    f"âœ… Dossiers d'analyse trouvÃ©s: {len(analysis_dirs)}")
            else:
                logger.error(f"âŒ Dossier d'analyse non trouvÃ©")
                all_files_exist = False
        else:
            if file_pattern.exists():
                logger.info(f"âœ… Fichier trouvÃ©: {file_pattern}")
            else:
                logger.error(f"âŒ Fichier manquant: {file_pattern}")
                all_files_exist = False

    if not all_files_exist:
        logger.error("âŒ Certains fichiers sont manquants.")
        return False

    # Test 4: Analyse rapide des donnÃ©es (si les dÃ©pendances sont disponibles)
    logger.info("\nğŸ“‹ Test 4: Analyse rapide des donnÃ©es")

    try:
        import pandas as pd
        import numpy as np

        # Charger les donnÃ©es
        df = pd.read_csv(features_dir / "aggregated_comprehensive.csv")

        logger.info(
            f"âœ… DonnÃ©es chargÃ©es: {len(df)} vidÃ©os, {len(df.columns)} features")

        # Statistiques de base
        if 'view_count' in df.columns:
            view_stats = df['view_count'].describe()
            logger.info(f"ğŸ“Š Statistiques des vues:")
            logger.info(f"   â€¢ Moyenne: {view_stats['mean']:,.0f}")
            logger.info(f"   â€¢ MÃ©diane: {view_stats['50%']:,.0f}")
            logger.info(f"   â€¢ Min: {view_stats['min']:,.0f}")
            logger.info(f"   â€¢ Max: {view_stats['max']:,.0f}")

        # VÃ©rifier les features
        feature_cols = [col for col in df.columns if col not in [
            'video_id', 'view_count', 'account_name']]
        logger.info(f"ğŸ”§ Features disponibles: {len(feature_cols)}")

        # Afficher quelques features
        for i, feature in enumerate(feature_cols[:10], 1):
            logger.info(f"   {i:2d}. {feature}")

        if len(feature_cols) > 10:
            logger.info(f"   ... et {len(feature_cols) - 10} autres")

    except ImportError as e:
        logger.warning(f"âš ï¸ DÃ©pendances manquantes pour l'analyse: {e}")
        logger.info(
            "   Installer: pip install pandas numpy matplotlib scikit-learn")
    except Exception as e:
        logger.error(f"âŒ Erreur lors de l'analyse: {e}")

    # RÃ©sumÃ© final
    print("\n" + "="*80)
    print("âœ… TEST POC TERMINÃ‰")
    print("="*80)
    print("ğŸ“Š RÃ©sultats:")
    print("   â€¢ Pipeline: âœ… Fonctionnel")
    print("   â€¢ AgrÃ©gation: âœ… Fonctionnelle")
    print("   â€¢ Fichiers: âœ… GÃ©nÃ©rÃ©s")
    print("   â€¢ DonnÃ©es: âœ… Valides")
    print("\nğŸ¯ Prochaines Ã©tapes:")
    print("   1. Analyser les donnÃ©es avec: python scripts/analyze_poc_data.py --dataset-dir data/dataset_poc_test")
    print("   2. CrÃ©er un modÃ¨le baseline")
    print("   3. Augmenter le dataset pour l'entraÃ®nement")

    return True


def main():
    """Main function."""
    logger = setup_logging()

    try:
        success = test_poc_pipeline()
        return 0 if success else 1

    except Exception as e:
        logger.error(f"âŒ Erreur lors du test: {e}")
        return 1


if __name__ == "__main__":
    exit(main())
