# üî¨ ITER_004: Dataset Cleaning & Feature Engineering

## üìã **Informations G√©n√©rales**

- **It√©ration ID**: `ITER_004`
- **Date de d√©but**: `2025-07-06`
- **Date de fin**: `[En cours]`
- **Responsable**: `√âquipe POC`
- **Version du mod√®le**: `iter_004`

---

## üéØ **Hypoth√®se de Recherche**

### **Question Principale**

> Le nettoyage du dataset et l'am√©lioration des features peuvent-ils r√©soudre l'overfitting et am√©liorer la g√©n√©ralisation du mod√®le ?

### **Hypoth√®ses Test√©es**

1. **H1**: Supprimer les duplications (62%) am√©liore la g√©n√©ralisation
2. **H2**: √âquilibrer la distribution par compte r√©duit le biais
3. **H3**: Nouvelles features bas√©es sur la qualit√© > quantit√© am√©liorent les pr√©dictions
4. **H4**: Validation crois√©e stratifi√©e par compte mesure mieux la g√©n√©ralisation

### **Objectifs Sp√©cifiques**

- [ ] Nettoyer le dataset en supprimant les duplications
- [ ] √âquilibrer la distribution par compte (max 10 vid√©os/compte)
- [ ] Impl√©menter de nouvelles features de qualit√©
- [ ] Entra√Æner un nouveau mod√®le sur le dataset propre
- [ ] Valider avec cross-validation stratifi√©e
- [ ] Comparer les performances avec ITER_003

---

## üìä **Variables Exp√©rimentales**

### **Variables Constantes**

| Variable          | Valeur                    | Justification               |
| ----------------- | ------------------------- | --------------------------- |
| **Mod√®le ML**     | `XGBoost`                 | Meilleur performer ITER_003 |
| **Feature set**   | `model_compatible`        | 16 features de base         |
| **Validation**    | `Cross-validation 5-fold` | Validation robuste          |
| **API Framework** | `FastAPI`                 | Framework de production     |

### **Variables Manipul√©es**

| Variable         | Valeur Test√©e                   | Valeur Contr√¥le       | Impact sur le Code                       | Justification              |
| ---------------- | ------------------------------- | --------------------- | ---------------------------------------- | -------------------------- |
| **Dataset**      | `Nettoy√© (sans duplications)`   | `ITER_002 (dupliqu√©)` | `scripts/clean_dataset.py`               | R√©soudre l'overfitting     |
| **Distribution** | `√âquilibr√©e (max 10/compte)`    | `D√©s√©quilibr√©e`       | `scripts/balance_dataset.py`             | R√©duire le biais de compte |
| **Features**     | `Nouvelles features de qualit√©` | `16 features de base` | `src/features/modular_feature_system.py` | Am√©liorer les pr√©dictions  |
| **Validation**   | `Stratifi√©e par compte`         | `Random CV`           | `scripts/train_model.py`                 | Mesurer la g√©n√©ralisation  |

---

## üî¨ **Protocole Exp√©rimental**

### **Phase 1: Nettoyage du Dataset** üßπ

```bash
# Supprimer les duplications
python scripts/clean_dataset.py --input data/dataset_iter_002/features/aggregated_comprehensive.csv --output data/dataset_iter_004_clean/clean_dataset.csv --max-videos-per-account 10

# √âquilibrer la distribution par compte
python scripts/balance_dataset.py --input data/dataset_iter_004_clean/clean_dataset.csv --max-videos-per-account 10 --output data/dataset_iter_004_clean/balanced_dataset.csv
```

**R√©sultats**:

- **Dataset original**: 84 vid√©os (62% duplications)
- **Dataset nettoy√©**: 20 vid√©os (0% duplications)
- **Distribution**: 2 comptes √©quilibr√©s (10 vid√©os chacun)

### üîß **Corrections Apport√©es - Phase 1**

### **Probl√®mes Identifi√©s et R√©solus**

#### **1. Crit√®res de Validation Trop Stricts** ‚úÖ Corrig√©

**Probl√®me**: Les crit√®res de validation rejetaient trop de vid√©os valides

- `min_views = 1000` ‚Üí Rejetait les vid√©os avec < 1000 vues
- `max_video_age_days = 180` ‚Üí Rejetait les vid√©os > 6 mois
- `min_video_duration = 1` ‚Üí Rejetait les vid√©os < 1 seconde

**Solution**: Crit√®res assouplis dans `src/utils/data_validator.py`

```python
# AVANT (trop strict)
self.min_views = 1000
self.max_video_age_days = 180  # 6 mois
self.min_video_duration = 1  # seconde

# APR√àS (plus permissif)
self.min_views = 100  # 10x plus permissif
self.max_video_age_days = 365  # 1 an au lieu de 6 mois
self.min_video_duration = 0.5  # 0.5 seconde au lieu de 1
```

#### **2. Limitation Artificielle du Nettoyage** ‚úÖ Corrig√©

**Probl√®me**: Le script de nettoyage limitait artificiellement √† 10 vid√©os par compte

- Dataset original: 84 vid√©os ‚Üí 20 vid√©os (perte de 64 vid√©os)

**Solution**: Limitation augment√©e dans `scripts/clean_dataset.py`

```python
# AVANT
def clean_dataset(input_file, output_file, max_videos_per_account=10):

# APR√àS
def clean_dataset(input_file, output_file, max_videos_per_account=20):
```

#### **3. Analyse des Duplications** ‚úÖ Ajout√©e

**Probl√®me**: 61.9% de duplications dans ITER_002 (52/84 vid√©os)

- M√™mes vid√©os attribu√©es √† 3 comptes diff√©rents
- Seulement 32 vid√©os uniques sur 84 total

**Solution**: Script d'analyse des duplications ajout√©

```bash
python scripts/analyze_dataset.py --input data/dataset_iter_002/features/aggregated_comprehensive.csv --analyze-duplications
```

### **R√©sultats des Corrections**

**Dataset ITER_002**:

- **Avant**: 20 vid√©os (crit√®res stricts)
- **Apr√®s**: 32 vid√©os (crit√®res assouplis)
- **Am√©lioration**: +60% de vid√©os conserv√©es

**Validation des Crit√®res**:

- ‚úÖ Plus de vid√©os conserv√©es lors du scraping
- ‚úÖ Crit√®res plus r√©alistes pour TikTok
- ‚úÖ Meilleure repr√©sentation de la diversit√©

### **Phase 2: Collecte de Donn√©es Diversifi√©es** üìä

```bash
# Collecte avec randomisation et diversit√©
python scripts/run_pipeline.py --dataset iter_004_diverse --batch-size 3 --videos-per-account 10 --max-total-videos 150 --enable-diversity --random-seed 42 --max-accounts 15 --feature-set comprehensive

# Collecte simple avec randomisation
python scripts/run_pipeline.py --dataset iter_004_random --batch-size 5 --videos-per-account 10 --max-total-videos 200 --random-seed 123
```

**Nouvelles Fonctionnalit√©s**:

- **Randomisation des comptes**: S√©lection al√©atoire pour √©viter les biais
- **Diversit√© par cat√©gories**: Assure la repr√©sentation de diff√©rents types de contenu
- **Contr√¥le de la randomisation**: Seed reproductible et limite de comptes
- **Batches diversifi√©s**: M√©lange de cat√©gories dans chaque batch

**Cat√©gories de Comptes**:

- **Lifestyle**: @leaelui, @unefille.ia, @lea*mary, @marie29france*
- **Tech**: @swarecito, @julien.snsn, @david_sepahan
- **Food**: @swiss_fit.cook, @healthyfood_creation, @pastelcuisine
- **Gaming**: @gotaga, @domingo, @squeezie, @sosah1.6
- **Humor**: @athenasol, @isabrunellii, @contiped
- **Travel**: @loupernaut, @astucequotidienne87
- **Fitness**: @oceane_dmg

### **Phase 3: Nouvelles Features** üÜï

```bash
# Impl√©menter les nouvelles features
# - hashtag_quality_score
# - creator_popularity_bias
# - content_uniqueness_score
# - completion_rate_estimate

# Tester les nouvelles features
python scripts/test_new_features.py --dataset data/dataset_iter_004_clean/balanced_dataset.csv
```

**Nouvelles Features**:

- `hashtag_quality_score`: Qualit√© vs quantit√© des hashtags
- `creator_popularity_bias`: Correction du biais de popularit√©
- `content_uniqueness_score`: Mesure d'unicit√© du contenu
- `completion_rate_estimate`: Estimation du taux de completion

### **Phase 4: Entra√Ænement du Mod√®le** ü§ñ

```bash
# Entra√Æner avec validation stratifi√©e
python scripts/train_model_iter_004.py --dataset data/dataset_iter_004_clean/balanced_dataset.csv --feature-set enhanced --validation-strategy stratified --save-model
```

**M√©triques √† surveiller**:

- **R¬≤ Score** (objectif: > 0.6 avec g√©n√©ralisation)
- **MAE** (objectif: < 0.3)
- **RMSE** (objectif: < 0.4)
- **G√©n√©ralisation** (objectif: R¬≤ > 0.5 sur comptes non vus)

### **Phase 5: Validation et Tests** ‚úÖ

```bash
# Tests sur nouveaux comptes
python scripts/test_generalization.py --model models/iter_004_xgboost_model.pkl --test-accounts new_accounts.txt

# Tests API
python scripts/test_api_iter_004.py
```

### **Phase 6: Documentation et Contenu √âducatif** üìö

- [ ] Mettre √† jour `docs/iterations/ITER_004_dataset_cleaning.md`
- [ ] Cr√©er contenu TikTok sur le nettoyage de donn√©es
- [ ] Documenter les nouvelles features

---

## üìä **R√©sultats et Insights**

### **Phase 1: Nettoyage du Dataset** ‚úÖ

**R√©sultats**:

- **Dataset original**: 84 vid√©os (62% duplications)
- **Dataset nettoy√©**: 20 vid√©os (0% duplications)
- **Distribution**: 2 comptes √©quilibr√©s (10 vid√©os chacun)

### **Phase 2: Collecte de Donn√©es Diversifi√©es** ‚úÖ

**Test de Randomisation R√©ussi**:

```bash
# Test avec 5 comptes, randomisation activ√©e
python scripts/run_pipeline.py --dataset test_randomization --batch-size 2 --videos-per-account 3 --max-total-videos 20 --enable-diversity --random-seed 123 --max-accounts 5 --feature-set comprehensive
```

**R√©sultats du Test**:

- ‚úÖ **Randomisation fonctionnelle**: 5 comptes s√©lectionn√©s al√©atoirement
- ‚úÖ **Diversit√© par cat√©gories**: Batches m√©langent food, gaming, humor
- ‚úÖ **Gestion d'erreurs**: 1 compte invalide d√©tect√© et ignor√©
- ‚úÖ **Agr√©gation automatique**: 12 features agr√©g√©es de 4 comptes
- ‚úÖ **Performance**: 8 vid√©os collect√©es en ~3 minutes

**Comptes Trait√©s**:

- **Batch 1**: @healthyfood_creation (food), @gotaga (gaming) - 4 vid√©os
- **Batch 2**: @squeezie (gaming), @isabrunellii@domingo (√©chec) - 3 vid√©os
- **Batch 3**: @sosah1.6 (gaming) - 1 vid√©o

**Nouvelles Fonctionnalit√©s Valid√©es**:

- **`--random-seed`**: Contr√¥le la reproductibilit√© (seed=123)
- **`--enable-diversity`**: Active la s√©lection par cat√©gories
- **`--max-accounts`**: Limite le nombre de comptes trait√©s
- **Logs am√©lior√©s**: Affichage des cat√©gories dans chaque batch

### **Phase 3: Nouvelles Features** üÜï

```bash
# Test des nouvelles features de qualit√©
python scripts/test_new_features.py --input data/dataset_iter_004_clean/cleaned_dataset.csv
```

**Features Ajout√©es**:

- `hashtag_quality_score`: Qualit√© des hashtags utilis√©s
- `creator_bias_factor`: Biais du cr√©ateur
- `content_uniqueness`: Unicit√© du contenu
- `completion_rate_estimate`: Estimation du taux de completion

### **Phase 4: Entra√Ænement du Mod√®le** ü§ñ

```bash
# Entra√Ænement avec validation crois√©e stratifi√©e
python scripts/train_xgboost_model.py --input data/dataset_iter_004_clean/balanced_dataset.csv --cv-folds 5 --stratified
```

**M√©triques Objectifs**:

- **R¬≤ Score** (objectif: > 0.6)
- **G√©n√©ralisation** (objectif: R¬≤ > 0.5 sur comptes non vus)

### **Phase 5: Validation et Tests** ‚úÖ

```bash
# Tests complets
python scripts/test_model_final.py --model models/iter_004_xgboost.pkl --test-data data/dataset_iter_004_clean/test_set.csv
```

### **Phase 6: Documentation et Contenu √âducatif** üìö

- [ ] Mettre √† jour `docs/iterations/ITER_004_dataset_cleaning.md`
- [ ] Cr√©er contenu TikTok sur la diversit√© des donn√©es
- [ ] Documenter les nouvelles features

---

## üéØ **Situation Actuelle et Recommandations**

### **üìä Analyse de la Situation**

**Dataset Actuel (ITER_002)**:

- **20 vid√©os** de **2 comptes** seulement
- **Probl√®mes identifi√©s**:
  - Dataset trop petit (besoin de 100+ vid√©os)
  - Manque de diversit√© des comptes (besoin de 10+ comptes)
  - Corr√©lations faibles avec les vues (seulement 2 corr√©lations > 0.3)

**Corr√©lations Actuelles**:

- `like_count`: 0.979 (tr√®s forte)
- `comment_count`: 0.966 (tr√®s forte)
- `share_count`: 0.608 (mod√©r√©e)
- `hour_of_day`: 0.353 (faible)
- Autres features: corr√©lations tr√®s faibles (< 0.3)

### **üöÄ Plan de Collecte ITER_004**

**Objectifs**:

- **150 vid√©os** de **15 comptes** diversifi√©s
- **10 vid√©os par compte** (√©quilibr√©)
- **6 cat√©gories** repr√©sent√©es

**Commande de Collecte**:

```bash
python scripts/run_pipeline.py --dataset iter_004_diverse --batch-size 3 --videos-per-account 10 --max-total-videos 150 --enable-diversity --random-seed 42 --max-accounts 15 --feature-set comprehensive
```

**Cat√©gories Cibles**:

- **Lifestyle**: @leaelui, @unefille.ia, @lea*mary, @marie29france*
- **Tech**: @swarecito, @julien.snsn, @david_sepahan
- **Food**: @swiss_fit.cook, @healthyfood_creation, @pastelcuisine
- **Gaming**: @gotaga, @domingo, @squeezie, @sosah1.6
- **Humor**: @athenasol, @isabrunellii, @contiped
- **Travel**: @loupernaut, @astucequotidienne87

### **‚úÖ Scripts Document√©s et Pr√™ts**

**Scripts de Data Processing**:

- ‚úÖ `scripts/clean_dataset.py` - Nettoyage et d√©duplication
- ‚úÖ `scripts/balance_dataset.py` - √âquilibrage par compte
- ‚úÖ `scripts/analyze_dataset.py` - Analyse et recommandations

**Scripts de Collecte**:

- ‚úÖ `scripts/run_pipeline.py` - Pipeline principal avec randomisation
- ‚úÖ `scripts/aggregate_features.py` - Agr√©gation automatique

**Fichiers Supprim√©s**:

- ‚ùå 10+ datasets de test obsol√®tes
- ‚ùå Scripts de test redondants
- ‚úÖ Structure simplifi√©e et organis√©e

### **üéØ Prochaines √âtapes**

1. **Collecte de Donn√©es** (1-2 jours):

   ```bash
   python scripts/run_pipeline.py --dataset iter_004_diverse --enable-diversity --max-accounts 15
   ```

2. **Nettoyage et √âquilibrage** (1 jour):

   ```bash
   python scripts/clean_dataset.py --input data/dataset_iter_004_diverse/features/aggregated_comprehensive.csv --output data/dataset_iter_004_final/cleaned_dataset.csv --max-videos-per-account 10
   python scripts/balance_dataset.py --input data/dataset_iter_004_final/cleaned_dataset.csv --output data/dataset_iter_004_final/balanced_dataset.csv --max-videos-per-account 10
   ```

3. **Entra√Ænement du Mod√®le** (1 jour):

   ```bash
   python scripts/train_xgboost_model.py --input data/dataset_iter_004_final/balanced_dataset.csv --cv-folds 5 --stratified
   ```

4. **Validation et Tests** (1 jour):
   ```bash
   python scripts/test_model_final.py --model models/iter_004_xgboost.pkl
   ```

**Estimation Totale**: 4-5 jours pour ITER_004 complet

---

## üé¨ **Contenu √âducatif Cr√©√©**

### **Vid√©os TikTok**

- **Vid√©o 1**: "Comment nettoyer un dataset ML pour √©viter l'overfitting" - [√Ä cr√©er]
- **Vid√©o 2**: "Feature Engineering: Qualit√© vs Quantit√©" - [√Ä cr√©er]

### **Articles/Posts**

- **Article 1**: "ITER_004: Nettoyage de dataset et nouvelles features" - [√Ä cr√©er]
- **Article 2**: "Validation crois√©e stratifi√©e: Mesurer la vraie g√©n√©ralisation" - [√Ä cr√©er]

### **Documentation Mise √† Jour**

- [ ] `docs/iterations/ITER_004_dataset_cleaning.md` - Documentation compl√®te
- [ ] `src/features/modular_feature_system.py` - Nouvelles features
- [ ] `scripts/clean_dataset.py` - Script de nettoyage
- [ ] `scripts/balance_dataset.py` - Script d'√©quilibrage

---

## üîÑ **It√©ration Suivante**

### **Am√©liorations Identifi√©es**

1. **Collecte de Donn√©es Diversifi√©es** (Priorit√©: Haute)

   - **Description**: Collecter des donn√©es de cr√©ateurs √©mergents
   - **Effort estim√©**: 2 jours

2. **Features Avanc√©es** (Priorit√©: Moyenne)

   - **Description**: Features bas√©es sur l'analyse de contenu vid√©o
   - **Effort estim√©**: 3 jours

3. **Ensemble Methods** (Priorit√©: Basse)
   - **Description**: Combiner plusieurs mod√®les
   - **Effort estim√©**: 2 jours

### **Variables √† Tester**

1. **Diversit√© des Cr√©ateurs** - Inclure des cr√©ateurs √©mergents
2. **Features Vid√©o** - Analyse du contenu visuel
3. **Temporal Features** - Patterns temporels de viralit√©

### **Objectifs de la Prochaine It√©ration**

- [ ] Collecter des donn√©es de cr√©ateurs √©mergents
- [ ] Impl√©menter des features d'analyse vid√©o
- [ ] Tester avec un dataset plus diversifi√©
- [ ] Valider la g√©n√©ralisation sur nouveaux cr√©ateurs

---

## üìö **R√©f√©rences et Liens**

### **Documentation R√©f√©renc√©e**

- **Analyse ITER_003**: `docs/iterations/ITER_003_dataset_analysis.md`
- **Template It√©ration**: `docs/iterations/template_iteration.md`
- **Feature System**: `src/features/modular_feature_system.py`

### **Scripts Utilis√©s**

- **Nettoyage**: `scripts/clean_dataset.py`
- **√âquilibrage**: `scripts/balance_dataset.py`
- **Training**: `scripts/train_model_iter_004.py`
- **Testing**: `scripts/test_generalization.py`

### **Donn√©es et Mod√®les**

- **Dataset Original**: `data/dataset_iter_002/features/aggregated_comprehensive.csv`
- **Dataset Nettoy√©**: `data/dataset_iter_004_clean/`
- **Mod√®le**: `models/iter_004_xgboost_model.pkl`

---

## ‚úÖ **Checklist de Validation**

### **Avant de Commencer**

- [x] Template rempli compl√®tement
- [x] Hypoth√®ses clairement d√©finies
- [x] Variables exp√©rimentales identifi√©es
- [x] Protocole valid√©

### **Pendant l'Exp√©rimentation**

- [ ] Dataset nettoy√© et √©quilibr√©
- [ ] Nouvelles features impl√©ment√©es
- [ ] Mod√®le entra√Æn√© avec validation stratifi√©e
- [ ] Tests de g√©n√©ralisation effectu√©s

### **Apr√®s l'Exp√©rimentation**

- [ ] R√©sultats analys√©s et compar√©s
- [ ] Documentation mise √† jour
- [ ] Prochaine it√©ration planifi√©e
- [ ] Commit avec message descriptif

---

**Derni√®re mise √† jour**: `2025-07-06`
**Version**: `v1.0.0`
**Statut**: `üöÄ En cours - Phase 1: Nettoyage du Dataset`
