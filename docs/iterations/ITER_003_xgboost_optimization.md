# üî¨ ITER_003: XGBoost Model Optimization

## üìã **Informations de Base**

- **ID It√©ration**: ITER_003
- **Date de Cr√©ation**: 2025-07-06
- **Dur√©e Estim√©e**: 1-2 heures
- **Complexit√©**: Level 2 (Simple Enhancement)
- **Statut**: En Planification

---

## üéØ **Hypoth√®se Principale**

### **Hypoth√®se Test√©e**

> "XGBoost am√©liore la g√©n√©ralisation par rapport √† RandomForest sur le m√™me dataset de 84 vid√©os"

### **Justification Scientifique**

- **ITER_002** a montr√© un R¬≤ de 0.855 avec RandomForest mais un overfitting
- **XGBoost** est g√©n√©ralement plus robuste pour la g√©n√©ralisation
- Test d'une seule variable (algorithme) pour isoler l'effet du mod√®le

### **Pr√©diction**

- **R¬≤ attendu**: 0.875+ (am√©lioration de 2%+)
- **G√©n√©ralisation**: Pr√©dictions plus coh√©rentes sur nouvelles vid√©os
- **Latence**: < 2 secondes (maintenue)

---

## üìä **Variables Exp√©rimentales**

### **Variables Constantes**

| Variable       | Valeur                  | Justification                     |
| -------------- | ----------------------- | --------------------------------- |
| **Dataset**    | 84 vid√©os               | M√™me dataset qu'ITER_002 (agr√©g√©) |
| **Features**   | 16 features             | M√™me feature set (comprehensive)  |
| **Validation** | Cross-validation 5-fold | M√™me protocole de validation      |
| **Target**     | log(view_count)         | M√™me transformation de la cible   |

### **Variables Manipul√©es**

| Variable            | Valeur Test√©e     | Valeur Contr√¥le       | Impact sur le Code               | Justification           |
| ------------------- | ----------------- | --------------------- | -------------------------------- | ----------------------- |
| **Algorithme**      | XGBoost           | RandomForest          | `scripts/train_xgboost_model.py` | Test de g√©n√©ralisation  |
| **Hyperparam√®tres** | XGBoost optimis√©s | RandomForest baseline | Nouveau script                   | Optimisation sp√©cifique |
| **Mod√®le Version**  | iter_003          | iter_002              | `src/api/ml_model.py`            | Versioning des mod√®les  |

---

## üî¨ **Protocole Exp√©rimental**

### **Phase 1: Pr√©paration (15 min)**

```bash
# V√©rifier que ITER_002 est complet
ls -la data/dataset_iter_002/features/aggregated_comprehensive.csv

# V√©rifier les mod√®les existants
ls -la models/
```

**Objectifs**:

- [ ] Dataset ITER_002 disponible (84 vid√©os)
- [ ] Mod√®les ITER_002 sauvegard√©s
- [ ] Environnement pr√™t pour XGBoost

### **Phase 2: Entra√Ænement XGBoost (30 min)**

```bash
# Entra√Æner le mod√®le XGBoost
python3 scripts/train_xgboost_model.py
```

**Param√®tres XGBoost**:

- **n_estimators**: 200
- **max_depth**: 6
- **learning_rate**: 0.1
- **subsample**: 0.8
- **colsample_bytree**: 0.8

### **Phase 3: Comparaison (15 min)**

```bash
# Comparer les performances
python3 scripts/analyze_existing_data.py --dataset-dir data/dataset_iter_002 --feature-set comprehensive --save-model --model-name iter_003_xgboost
```

**M√©triques de Comparaison**:

- **R¬≤ Score** (objectif: > 0.875)
- **MAE** (objectif: < 0.3)
- **RMSE** (objectif: < 0.4)
- **G√©n√©ralisation** (test sur nouvelles vid√©os)

### **Phase 4: Test API (15 min)**

```bash
# Tester avec XGBoost
export ML_MODEL_TYPE=xgboost
export ML_MODEL_VERSION=iter_003
uvicorn src.api.main:app --reload --port 8000

# Test de pr√©diction
curl -X POST "http://localhost:8000/analyze-tiktok-url" \
  -H "Content-Type: application/json" \
  -d '{"url": "https://www.tiktok.com/@david_sepahan/video/7516571262638984470", "use_cache": false}'
```

### **Phase 5: Documentation (15 min)**

- [ ] Mettre √† jour ITER_003 avec r√©sultats
- [ ] Documenter les am√©liorations MLOps
- [ ] Planifier ITER_004

---

## üìà **M√©triques de Succ√®s**

### **Objectifs Techniques**

| M√©trique        | ITER_002 (RF) | ITER_003 (XGB) | Objectif | Statut |
| --------------- | ------------- | -------------- | -------- | ------ |
| **R¬≤ Score**    | 0.855         | ?              | > 0.875  | ‚è≥     |
| **MAE**         | ?             | ?              | < 0.3    | ‚è≥     |
| **RMSE**        | ?             | ?              | < 0.4    | ‚è≥     |
| **Latence API** | < 2s          | ?              | < 2s     | ‚è≥     |

### **Objectifs de G√©n√©ralisation**

- [ ] Pr√©diction coh√©rente sur vid√©o non-virale
- [ ] Score < 0.5 pour vid√©o avec 1,442 vues
- [ ] Am√©lioration de la robustesse

---

## üîß **Gestion MLOps**

### **Variables d'Environnement**

```bash
# Utiliser RandomForest (par d√©faut)
export ML_MODEL_TYPE=randomforest
export ML_MODEL_VERSION=iter_002

# Utiliser XGBoost
export ML_MODEL_TYPE=xgboost
export ML_MODEL_VERSION=iter_003
```

### **Fichiers de Mod√®les**

- `models/iter_002_model.pkl` - RandomForest ITER_002
- `models/iter_003_xgboost_model.pkl` - XGBoost ITER_003
- `models/iter_003_xgboost_metrics.json` - M√©triques XGBoost

### **Changement de Mod√®le**

```python
# Dans src/api/ml_model.py
self.model_type = os.getenv("ML_MODEL_TYPE", "randomforest")
self.model_version = os.getenv("ML_MODEL_VERSION", "iter_002")
```

---

## üé¨ **Contenu √âducatif Planifi√©**

### **Vid√©o TikTok**

- **Titre**: "XGBoost vs RandomForest: quel mod√®le pr√©dit mieux la viralit√©?"
- **Dur√©e**: 45 secondes
- **Th√®me**: Comparaison d'algorithmes ML
- **Hashtags**: #MachineLearning #XGBoost #RandomForest #DataScience

### **Documentation**

- [ ] Mise √† jour du glossaire ML
- [ ] Explication des diff√©rences XGBoost vs RandomForest
- [ ] Guide de choix d'algorithme

---

## üîÑ **It√©ration Suivante (ITER_004)**

### **Hypoth√®ses Possibles**

1. **Feature Engineering**: Nouvelles features bas√©es sur insights ITER_003
2. **Hyperparameter Tuning**: Optimisation avanc√©e des param√®tres
3. **Ensemble Methods**: Combinaison RandomForest + XGBoost

### **Variables √† Tester**

- **Feature Engineering**: Nouvelles features contextuelles
- **Hyperparameters**: Grid search pour XGBoost
- **Ensemble**: Voting regressor

---

## üìö **R√©f√©rences et Liens**

### **Documentation R√©f√©renc√©e**

- **Architecture MLOps**: `docs/iterations/architecture_mlops.md`
- **ITER_002**: `docs/iterations/ITER_002_feature_optimization.md`
- **Template**: `docs/iterations/template_iteration.md`

### **Scripts Utilis√©s**

- **XGBoost Training**: `scripts/train_xgboost_model.py`
- **Analyse Donn√©es**: `scripts/analyze_existing_data.py`
- **API Testing**: Tests manuels avec curl

### **Donn√©es et Mod√®les**

- **Dataset**: `data/dataset_iter_002/features/aggregated_comprehensive.csv`
- **Mod√®le RF**: `models/iter_002_model.pkl`
- **Mod√®le XGB**: `models/iter_003_xgboost_model.pkl`

---

## ‚úÖ **Checklist de Validation**

### **Avant de Commencer**

- [ ] Dataset ITER_002 disponible (84 vid√©os)
- [ ] Script XGBoost cr√©√© et test√©
- [ ] Variables d'environnement document√©es
- [ ] Protocole valid√©

### **Pendant l'Exp√©rimentation**

- [ ] XGBoost entra√Æn√© avec succ√®s
- [ ] Comparaison RandomForest vs XGBoost
- [ ] Tests API avec nouveau mod√®le
- [ ] M√©triques enregistr√©es

### **Apr√®s l'Exp√©rimentation**

- [ ] R√©sultats analys√©s et document√©s
- [ ] Mod√®le XGBoost sauvegard√©
- [ ] API configur√©e pour changement de mod√®le
- [ ] Prochaine it√©ration planifi√©e

---

**Cr√©√© le**: `2025-07-06`
**Derni√®re mise √† jour**: `2025-07-06`
**Version**: `v1.0.0`
