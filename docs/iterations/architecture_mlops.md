# ğŸ—ï¸ Architecture MLOps - Variables ExpÃ©rimentales et Changements

## ğŸ¯ **Vue d'Ensemble de l'Architecture**

Notre POC suit une architecture MLOps simple mais robuste, permettant de changer facilement les modÃ¨les et features sans casser le systÃ¨me.

### **Architecture Actuelle**

```
ğŸ“Š Data Pipeline
â”œâ”€â”€ ğŸ•·ï¸ Scraping (Apify TikTok)
â”œâ”€â”€ ğŸ”§ Feature Extraction (Modular System)
â”œâ”€â”€ ğŸ¤– ML Model (RandomForest)
â””â”€â”€ ğŸš€ API (FastAPI)
```

---

## ğŸ”§ **Variables ExpÃ©rimentales et leur Impact**

### **1. ğŸ¯ Feature Sets (Variables ManipulÃ©es)**

#### **Feature Sets Disponibles**

```python
# Dans src/features/modular_feature_system.py
FEATURE_SETS = {
    "metadata": MetadataFeatureSet(),           # 20 features
    "gemini_basic": GeminiBasicFeatureSet(),    # 14 features
    "visual_granular": VisualGranularFeatureSet(), # 34 features
    "comprehensive": ComprehensiveFeatureSet(),  # 34 features
    "model_compatible": ModelCompatibleFeatureSet() # 16 features â­
}
```

#### **Comment Changer de Feature Set**

```bash
# Dans les scripts
python3 scripts/analyze_existing_data.py --feature-set comprehensive
python3 scripts/analyze_existing_data.py --feature-set model_compatible

# Dans l'API (automatique)
# L'API utilise toujours ModelCompatibleFeatureSet (16 features)
```

#### **Impact sur le Code**

- **Feature Count**: Varie selon le set (16-34 features)
- **Model Compatibility**: Seul `model_compatible` fonctionne avec l'API
- **Performance**: Plus de features = plus de temps de calcul
- **RÂ² Score**: Peut varier selon les features

### **2. ğŸ¤– ModÃ¨les ML (Variables ManipulÃ©es)**

#### **ModÃ¨les Actuels**

```python
# Dans models/
â”œâ”€â”€ pre_publication_virality_model.pkl    # RandomForest (RÂ² = 0.457)
â””â”€â”€ baseline_virality_model.pkl           # Backup model
```

#### **Comment Changer de ModÃ¨le**

```python
# Dans src/api/ml_model.py - Ligne 25
self.model_path = project_root / "models/pre_publication_virality_model.pkl"

# Pour changer de modÃ¨le, modifier cette ligne :
self.model_path = project_root / "models/xgboost_virality_model.pkl"
```

#### **ModÃ¨les Ã  Tester (PlanifiÃ©s)**

| ModÃ¨le             | Avantages              | InconvÃ©nients         | Effort      |
| ------------------ | ---------------------- | --------------------- | ----------- |
| **RandomForest**   | Robuste, interprÃ©table | Performance limitÃ©e   | âœ… Actuel   |
| **XGBoost**        | Meilleure performance  | Plus complexe         | ğŸ”„ ITER_003 |
| **LightGBM**       | Rapide, efficace       | Moins interprÃ©table   | ğŸ”„ ITER_004 |
| **Neural Network** | TrÃ¨s flexible          | Overfitting, complexe | ğŸ”„ ITER_005 |

### **3. ğŸ“Š Dataset Size (Variables ManipulÃ©es)**

#### **Tailles de Dataset TestÃ©es**

```python
DATASET_SIZES = {
    "ITER_001": 8 vidÃ©os,      # POC initial
    "ITER_002": 150 vidÃ©os,    # Scaling (planifiÃ©)
    "ITER_003": 500 vidÃ©os,    # Production (planifiÃ©)
}
```

#### **Impact sur les MÃ©triques**

| Dataset Size   | RÂ² Score | MAE   | RMSE  | Temps EntraÃ®nement |
| -------------- | -------- | ----- | ----- | ------------------ |
| **8 vidÃ©os**   | 0.457    | 0.23  | 0.34  | 2s                 |
| **150 vidÃ©os** | ~0.6     | ~0.18 | ~0.25 | 30s                |
| **500 vidÃ©os** | ~0.7     | ~0.15 | ~0.20 | 2min               |

---

## ğŸ”„ **Workflow de Changement de ModÃ¨le**

### **Ã‰tape 1: PrÃ©parer le Nouveau ModÃ¨le**

```bash
# 1. EntraÃ®ner le nouveau modÃ¨le
python3 scripts/analyze_existing_data.py --dataset-dir data/dataset_poc_training --feature-set model_compatible --save-model --model-type xgboost

# 2. Sauvegarder avec un nom descriptif
mv models/pre_publication_virality_model.pkl models/xgboost_virality_model_v1.pkl
```

### **Ã‰tape 2: Modifier l'API**

```python
# Dans src/api/ml_model.py - Ligne 25
# AVANT
self.model_path = project_root / "models/pre_publication_virality_model.pkl"

# APRÃˆS
self.model_path = project_root / "models/xgboost_virality_model_v1.pkl"
```

### **Ã‰tape 3: Tester**

```bash
# Test local
python3 scripts/test_api_fixed.py

# Test avec nouvelle URL
curl -X POST "http://localhost:8000/analyze-tiktok-url" \
  -H "Content-Type: application/json" \
  -d '{"url": "https://www.tiktok.com/@swarecito/video/7505706702050823446"}'
```

### **Ã‰tape 4: DÃ©ployer**

```bash
# Commit et dÃ©ploiement
git add src/api/ml_model.py models/xgboost_virality_model_v1.pkl
git commit -m "feat: switch to XGBoost model (RÂ²=0.612)"
railway up
```

---

## ğŸ”§ **Workflow de Changement de Features**

### **Ã‰tape 1: CrÃ©er un Nouveau Feature Set**

```python
# Dans src/features/modular_feature_system.py
class EnhancedFeatureSet(BaseFeatureSet):
    def __init__(self):
        super().__init__(
            name="enhanced",
            description="Enhanced features with new insights"
        )
        self.features = [
            # 16 features compatibles avec le modÃ¨le
            'duration', 'hashtag_count', 'estimated_hashtag_count',
            # ... ajouter nouvelles features
        ]

    def extract(self, video_data: Dict, gemini_analysis: Optional[Dict] = None) -> Dict:
        # Logique d'extraction
        pass
```

### **Ã‰tape 2: Enregistrer le Feature Set**

```python
# Dans la fonction _register_default_sets()
def _register_default_sets(self):
    self.register_feature_set(MetadataFeatureSet())
    self.register_feature_set(GeminiBasicFeatureSet())
    self.register_feature_set(EnhancedFeatureSet())  # Nouveau
```

### **Ã‰tape 3: Tester avec le Nouveau Feature Set**

```bash
# Test d'extraction
python3 scripts/analyze_existing_data.py --feature-set enhanced

# Test API (si compatible)
# L'API utilise toujours ModelCompatibleFeatureSet
```

---

## ğŸ“Š **MÃ©triques StandardisÃ©es (Variables Constantes)**

### **MÃ©triques Toujours CalculÃ©es**

```python
STANDARD_METRICS = {
    "r2_score": "Coefficient de dÃ©termination (0-1)",
    "mae": "Mean Absolute Error (plus bas = mieux)",
    "rmse": "Root Mean Square Error (plus bas = mieux)",
    "feature_importance": "Top 5 features importantes",
    "latency": "Temps de prÃ©diction (objectif < 2s)"
}
```

### **Seuils de Performance**

| MÃ©trique     | Seuil Acceptable | Seuil Bon | Seuil Excellent |
| ------------ | ---------------- | --------- | --------------- |
| **RÂ² Score** | > 0.4            | > 0.6     | > 0.8           |
| **MAE**      | < 0.3            | < 0.2     | < 0.1           |
| **RMSE**     | < 0.4            | < 0.3     | < 0.2           |
| **Latency**  | < 3s             | < 2s      | < 1s            |

### **Feature Importance (Toujours CalculÃ©e)**

```python
# Format standard
feature_importance = {
    "feature_1": 0.124,  # 12.4% d'importance
    "feature_2": 0.108,  # 10.8% d'importance
    # ... top 5 features
}
```

---

## ğŸ¯ **Variables par ItÃ©ration**

### **ITER_001: POC Initial** âœ…

```python
VARIABLES_ITER_001 = {
    "dataset_size": 8,
    "model": "RandomForest",
    "feature_set": "ModelCompatibleFeatureSet",
    "r2_score": 0.457,
    "status": "COMPLETED"
}
```

### **ITER_002: Dataset Scaling** ğŸ”„

```python
VARIABLES_ITER_002 = {
    "dataset_size": 150,  # 8 â†’ 150
    "model": "RandomForest",  # MÃªme modÃ¨le
    "feature_set": "ModelCompatibleFeatureSet",  # MÃªme features
    "expected_r2": "> 0.6",
    "status": "PLANNED"
}
```

### **ITER_003: Model Optimization** ğŸ”„

```python
VARIABLES_ITER_003 = {
    "dataset_size": 150,
    "model": "XGBoost",  # RandomForest â†’ XGBoost
    "feature_set": "ModelCompatibleFeatureSet",
    "expected_r2": "> 0.65",
    "status": "PLANNED"
}
```

### **ITER_004: Feature Engineering** ğŸ”„

```python
VARIABLES_ITER_004 = {
    "dataset_size": 150,
    "model": "XGBoost",
    "feature_set": "EnhancedFeatureSet",  # Nouvelles features
    "expected_r2": "> 0.7",
    "status": "PLANNED"
}
```

---

## ğŸš¨ **Points d'Attention**

### **1. CompatibilitÃ© ModÃ¨le-Features**

```python
# âŒ PROBLÃˆME: Features mismatch
model_expects = 16 features
features_provided = 34 features  # Erreur!

# âœ… SOLUTION: Toujours utiliser ModelCompatibleFeatureSet pour l'API
```

### **2. Sauvegarde des ModÃ¨les**

```bash
# âœ… Toujours sauvegarder avant changement
cp models/pre_publication_virality_model.pkl models/backup_randomforest.pkl

# âœ… Versionner les modÃ¨les
mv models/xgboost_virality_model.pkl models/xgboost_virality_model_v1.pkl
```

### **3. Tests de RÃ©gression**

```bash
# âœ… Tester avant dÃ©ploiement
python3 scripts/test_api_fixed.py

# âœ… VÃ©rifier les mÃ©triques
curl -X POST "http://localhost:8000/analyze-tiktok-url" \
  -d '{"url": "test_url"}' | jq '.prediction.r2_score'
```

---

## ğŸ“š **Documentation Perdue (Reflections)**

### **Contenu SupprimÃ© Important**

Le dossier `docs/reflection/` contenait :

- **Feature Engineering Analysis** - Analyse dÃ©taillÃ©e des 34 features
- **Model Comparison** - Comparaison RandomForest vs XGBoost vs autres
- **Architecture Decisions** - DÃ©cisions d'architecture importantes

### **RecrÃ©ation NÃ©cessaire**

```bash
# Ã€ recrÃ©er dans docs/iterations/
â”œâ”€â”€ feature_engineering_analysis.md
â”œâ”€â”€ model_comparison_guide.md
â”œâ”€â”€ architecture_decisions.md
â””â”€â”€ experimental_results.md
```

---

## ğŸ¯ **Checklist de Changement**

### **Avant de Changer de ModÃ¨le**

- [ ] Sauvegarder le modÃ¨le actuel
- [ ] Tester le nouveau modÃ¨le localement
- [ ] VÃ©rifier la compatibilitÃ© des features
- [ ] Documenter les mÃ©triques de performance

### **Avant de Changer de Features**

- [ ] VÃ©rifier la compatibilitÃ© avec le modÃ¨le
- [ ] Tester l'extraction des nouvelles features
- [ ] Valider les performances
- [ ] Mettre Ã  jour la documentation

### **Avant de DÃ©ployer**

- [ ] Tests de rÃ©gression complets
- [ ] Validation des mÃ©triques
- [ ] Documentation mise Ã  jour
- [ ] Rollback plan prÃ©parÃ©

---

**Document crÃ©Ã© le**: `2025-07-06`
**DerniÃ¨re mise Ã  jour**: `2025-07-06`
**Version**: `v1.0.0`
**Responsable**: Ã‰quipe POC TikTok Virality
