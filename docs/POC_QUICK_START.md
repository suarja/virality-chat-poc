# ğŸš€ POC Quick Start - Virality Prediction

## ğŸ¯ Objectif

Valider rapidement l'idÃ©e de prÃ©diction de viralitÃ© TikTok en testant le pipeline end-to-end et en crÃ©ant un modÃ¨le baseline.

## âš¡ DÃ©marrage ImmÃ©diat (5 minutes)

### 1. Test Rapide du Pipeline (avec agrÃ©gation automatique)

```bash
# Test avec 6 vidÃ©os seulement (agrÃ©gation automatique incluse)
python3 scripts/test_pipeline_with_aggregation.py
```

**Ce test va :**

- âœ… Scraper 3 vidÃ©os de 1 compte
- âœ… Analyser avec Gemini AI
- âœ… Extraire les features
- âœ… **AgrÃ©ger automatiquement** les donnÃ©es
- âœ… VÃ©rifier que tout fonctionne

### 2. Analyse des DonnÃ©es Existantes

```bash
# Si tu as dÃ©jÃ  des donnÃ©es, analyser sans relancer le pipeline
python3 scripts/check_poc_data.py --dataset-dir data/dataset_poc_test --aggregate

# Ou analyser avec dÃ©pendances (si installÃ©es)
pip install pandas numpy matplotlib scikit-learn
python3 scripts/analyze_existing_data.py --dataset-dir data/dataset_poc_test --save-model
```

**Cette analyse va :**

- ğŸ“Š Analyser la distribution des donnÃ©es
- ğŸ”— Calculer les corrÃ©lations
- ğŸ¤– CrÃ©er un modÃ¨le baseline
- ğŸ’¡ GÃ©nÃ©rer des insights

## ğŸ“‹ Plan Complet (3 semaines)

### **Semaine 1 : Validation Rapide**

```bash
# Jour 1-2 : Test pipeline avec agrÃ©gation automatique
python3 scripts/test_pipeline_with_aggregation.py

# Jour 3-4 : Analyse et modÃ¨le baseline
python3 scripts/analyze_existing_data.py --dataset-dir data/dataset_poc_test_aggregation --save-model

# Jour 5 : Ã‰valuation et planification
```

### **Semaine 2 : DÃ©veloppement du ModÃ¨le**

```bash
# Jour 1-2 : Dataset d'entraÃ®nement (150 vidÃ©os)
python3 scripts/run_pipeline.py --dataset poc_training --batch-size 3 --videos-per-account 15 --max-total-videos 150 --feature-system modular --feature-set comprehensive

# Jour 3-4 : ModÃ¨le avancÃ©
python3 scripts/train_advanced_model.py --dataset-dir data/dataset_poc_training

# Jour 5 : API de prÃ©diction
python3 scripts/create_prediction_api.py
```

### **Semaine 3 : DÃ©mo et Validation**

```bash
# Jour 1-2 : DÃ©mo Upwork
python3 scripts/generate_virality_report.py --video-urls urls.txt

# Jour 3-4 : IntÃ©gration app mobile
# (Code JavaScript/React Native)

# Jour 5 : Tests et optimisations
```

## ğŸ¯ MÃ©triques de SuccÃ¨s

### **Techniques (Phase 1)**

- âœ… **Pipeline fonctionnel** end-to-end
- âœ… **AgrÃ©gation automatique** des features
- âœ… **RÂ² Score > 0.4** sur validation croisÃ©e
- âœ… **Features extraites** correctement
- âœ… **DonnÃ©es valides** et cohÃ©rentes

### **Business (Phase 3)**

- âœ… **DÃ©mo Upwork** prÃªte
- âœ… **Rapport PDF** professionnel
- âœ… **API fonctionnelle** pour l'app
- âœ… **Insights actionnables** gÃ©nÃ©rÃ©s

## ğŸš¨ DÃ©pannage Rapide

### **Erreur de dÃ©pendances**

```bash
pip install pandas numpy matplotlib scikit-learn seaborn
```

### **Erreur de pipeline**

```bash
# VÃ©rifier les logs
tail -f logs/pipeline_poc_test_aggregation.log

# VÃ©rifier les erreurs
tail -f logs/errors.log
```

### **Erreur d'API Gemini**

```bash
# VÃ©rifier la clÃ© API
echo $GEMINI_API_KEY

# Tester l'API
python3 scripts/test_gemini.py
```

### **Fichier agrÃ©gÃ© manquant**

```bash
# AgrÃ©gation manuelle si nÃ©cessaire
python3 scripts/aggregate_features.py --dataset-dir data/dataset_poc_test --feature-set comprehensive --show-stats
```

## ğŸ“Š Structure des DonnÃ©es

```
data/dataset_poc_test_aggregation/
â”œâ”€â”€ batch_20241201_143022.json    # DonnÃ©es scrapÃ©es
â”œâ”€â”€ gemini_analysis/              # Analyses Gemini
â”‚   â””â”€â”€ @account_name/
â”‚       â””â”€â”€ 20241201/
â”‚           â””â”€â”€ video_*.json
â””â”€â”€ features/                     # Features extraites
    â”œâ”€â”€ @account_name_features_comprehensive.csv  # Par compte
    â””â”€â”€ aggregated_comprehensive.csv              # AgrÃ©gÃ© automatiquement
```

## ğŸ¯ Prochaines Ã‰tapes

### **Si le test rapide rÃ©ussit :**

1. **Augmenter le dataset** Ã  150 vidÃ©os
2. **Optimiser le modÃ¨le** (Gradient Boosting, XGBoost)
3. **CrÃ©er l'API** de prÃ©diction
4. **PrÃ©parer la dÃ©mo** Upwork

### **Si le test Ã©choue :**

1. **Analyser les erreurs** dans les logs
2. **Corriger les problÃ¨mes** identifiÃ©s
3. **Retester** avec moins de vidÃ©os
4. **ConsidÃ©rer un pivot** vers Account Analyzer

## ğŸ’¡ Tips pour le POC

### **Optimisation des CoÃ»ts**

- Commencer avec **6 vidÃ©os** seulement
- Utiliser **batch-size=1** pour Ã©viter les erreurs
- **Tester localement** avant de scaler

### **Optimisation du Temps**

- **AgrÃ©gation automatique** incluse dans le pipeline
- **ParallÃ©liser** les phases quand possible
- **Cacher les rÃ©sultats** pour Ã©viter les re-calculs
- **Logs dÃ©taillÃ©s** pour le debugging

### **QualitÃ© des DonnÃ©es**

- **Valider** chaque phase avant de continuer
- **VÃ©rifier** la cohÃ©rence des features
- **Nettoyer** les donnÃ©es aberrantes

## ğŸ¯ Commandes de Test Rapide

```bash
# Test minimal avec agrÃ©gation automatique (5 minutes)
python3 scripts/test_pipeline_with_aggregation.py

# Test avec analyse des donnÃ©es existantes (2 minutes)
python3 scripts/check_poc_data.py --dataset-dir data/dataset_poc_test --aggregate

# Test complet (30 minutes)
python3 scripts/run_pipeline.py --dataset poc_validation --batch-size 2 --videos-per-account 10 --max-total-videos 40 --feature-system modular --feature-set comprehensive
```

## ğŸ”§ Scripts Disponibles

### **Pipeline et Tests**

- `scripts/test_pipeline_with_aggregation.py` - Test complet avec agrÃ©gation automatique
- `scripts/test_poc_pipeline.py` - Test basique du pipeline
- `scripts/run_pipeline.py` - Pipeline principal

### **Analyse des DonnÃ©es**

- `scripts/check_poc_data.py` - VÃ©rification simple sans dÃ©pendances
- `scripts/analyze_existing_data.py` - Analyse complÃ¨te avec ML
- `scripts/aggregate_features.py` - AgrÃ©gation manuelle si nÃ©cessaire

### **Utilitaires**

- `scripts/analyze_poc_data.py` - Analyse avec visualisations (dÃ©pendances requises)

**PrÃªt Ã  commencer ?** ğŸš€

```bash
# Commencer maintenant
python3 scripts/test_pipeline_with_aggregation.py
```
