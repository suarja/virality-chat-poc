# Guide de D√©veloppement - Virality Chat POC

## üöÄ D√©marrage Rapide

### 1. Configuration initiale

```bash
# Cloner le projet
git clone <repository-url>
cd virality-chat-poc

# Ex√©cuter le script de setup
python scripts/setup_project.py

# Activer l'environnement virtuel
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate     # Windows

# Configurer les cl√©s API
cp env.template .env
# √âditer .env avec vos cl√©s API
```

### 2. Structure du projet

```
virality-chat-poc/
‚îú‚îÄ‚îÄ config/                 # Configuration
‚îÇ   ‚îî‚îÄ‚îÄ settings.py
‚îú‚îÄ‚îÄ data/                   # Donn√©es
‚îÇ   ‚îú‚îÄ‚îÄ raw/               # Donn√©es brutes
‚îÇ   ‚îú‚îÄ‚îÄ processed/         # Donn√©es trait√©es
‚îÇ   ‚îî‚îÄ‚îÄ external/          # Donn√©es externes
‚îú‚îÄ‚îÄ docs/                   # Documentation
‚îÇ   ‚îú‚îÄ‚îÄ prd.md
‚îÇ   ‚îî‚îÄ‚îÄ development_guide.md
‚îú‚îÄ‚îÄ notebooks/              # Notebooks Jupyter
‚îÇ   ‚îú‚îÄ‚îÄ exploration/
‚îÇ   ‚îú‚îÄ‚îÄ modeling/
‚îÇ   ‚îî‚îÄ‚îÄ demo/
‚îú‚îÄ‚îÄ src/                    # Code source
‚îÇ   ‚îú‚îÄ‚îÄ scraping/          # Scraping TikTok
‚îÇ   ‚îú‚îÄ‚îÄ features/          # Feature engineering
‚îÇ   ‚îú‚îÄ‚îÄ models/            # Mod√®les ML
‚îÇ   ‚îî‚îÄ‚îÄ api/               # API et services
‚îú‚îÄ‚îÄ streamlit_app/          # Interface Streamlit
‚îú‚îÄ‚îÄ reports/                # Rapports et r√©sultats
‚îú‚îÄ‚îÄ scripts/                # Scripts utilitaires
‚îî‚îÄ‚îÄ requirements.txt
```

## üìã Workflow de D√©veloppement

### Phase 1: Foundation Sprint (Jours 1-2)

**Objectif**: Collecte et exploration des donn√©es

1. **Scraping des donn√©es**

   ```bash
   # Configurer les comptes TikTok dans config/settings.py
   # Ex√©cuter le scraping
   python -m src.scraping.tiktok_scraper
   ```

2. **Exploration des donn√©es**

   ```bash
   # Ouvrir le notebook d'exploration
   jupyter notebook notebooks/01_data_exploration.ipynb
   ```

3. **Validation des donn√©es**
   ```python
   from src.scraping.data_validator import DataValidator
   validator = DataValidator()
   clean_data = validator.clean_dataset(raw_videos)
   ```

### Phase 2: Core MVP Sprint (Jours 3-5)

**Objectif**: Feature engineering et mod√®le baseline

1. **Feature engineering**

   - Extraction des features de base (vues, likes, etc.)
   - Analyse des hashtags et du texte
   - Features temporelles

2. **Mod√®le baseline**

   ```python
   from sklearn.ensemble import RandomForestClassifier
   from sklearn.model_selection import train_test_split

   # Entra√Æner le mod√®le
   X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
   model = RandomForestClassifier(random_state=42)
   model.fit(X_train, y_train)
   ```

3. **Interface Streamlit**
   ```bash
   # Lancer l'app Streamlit
   streamlit run streamlit_app/app.py
   ```

### Phase 3: Enhancement Sprint (Jours 6-8)

**Objectif**: Am√©lioration du mod√®le et insights

1. **Feature engineering avanc√©**

   - Int√©gration Gemini API pour analyse vid√©o
   - Features s√©mantiques et visuelles
   - Optimisation des hyperparam√®tres

2. **Interpr√©tabilit√©**

   ```python
   import shap

   # Analyse SHAP
   explainer = shap.TreeExplainer(model)
   shap_values = explainer.shap_values(X_test)
   shap.summary_plot(shap_values, X_test)
   ```

### Phase 4: Packaging Sprint (Jours 9-10)

**Objectif**: Documentation et livraison

1. **Documentation compl√®te**
2. **Rapport final** (Quarto/Jupyter)
3. **Vid√©o de d√©monstration**
4. **Contenu marketing**

## üîß Outils et Technologies

### Stack Principal

- **Python 3.9+**: Langage principal
- **pandas**: Manipulation des donn√©es
- **scikit-learn**: Machine learning
- **Streamlit**: Interface utilisateur
- **Jupyter**: Notebooks d'exploration
- **Plotly**: Visualisations interactives

### APIs Externes

- **Apify**: Scraping TikTok
- **Gemini API**: Analyse vid√©o IA
- **OpenAI** (optionnel): Backup pour l'analyse

### Outils de D√©veloppement

- **Git**: Contr√¥le de version
- **Black**: Formatage du code
- **pytest**: Tests unitaires
- **Quarto**: Documentation

## üìä M√©triques et Validation

### M√©triques ML

- **Accuracy**: Pr√©cision globale
- **Precision/Recall**: Par classe de viralit√©
- **F1-Score**: M√©trique √©quilibr√©e
- **ROC-AUC**: Discrimination des classes

### M√©triques Business

- **Taux de pr√©diction correct**: >70%
- **Temps de traitement**: <5 secondes par vid√©o
- **Couverture des features**: >20 features significatives

## üö® Bonnes Pratiques

### Code

- Suivre PEP 8 pour le style Python
- Documenter les fonctions avec docstrings
- Utiliser des noms de variables explicites
- G√©rer les erreurs avec try/except

### Donn√©es

- Valider les donn√©es avant traitement
- Sauvegarder les donn√©es brutes
- Versionner les datasets trait√©s
- Documenter les transformations

### S√©curit√©

- Ne jamais committer les cl√©s API
- Utiliser .env pour les secrets
- Limiter les permissions des APIs
- Respecter les rate limits

## üêõ Debugging

### Probl√®mes Courants

1. **Erreur d'import**

   ```bash
   # V√©rifier le PYTHONPATH
   export PYTHONPATH="${PYTHONPATH}:$(pwd)/src"
   ```

2. **API Rate Limit**

   ```python
   import time
   time.sleep(2)  # Pause entre les requ√™tes
   ```

3. **Donn√©es manquantes**
   ```python
   df.fillna(method='ffill')  # Forward fill
   ```

### Logs

- Utiliser le module `logging` Python
- Niveaux: DEBUG, INFO, WARNING, ERROR
- Logs sauvegard√©s dans `logs/`

## üìà Monitoring

### M√©triques √† suivre

- Nombre de vid√©os scrapp√©es
- Taux de succ√®s du scraping
- Performance du mod√®le
- Utilisation des APIs

### Alertes

- √âchec du scraping
- D√©passement des quotas API
- Chute de performance du mod√®le

## üéØ Prochaines √âtapes

1. **V2 Features**

   - Analyse temporelle des tendances
   - Segmentation par niche
   - API REST pour int√©gration

2. **D√©ploiement**

   - Conteneurisation Docker
   - D√©ploiement cloud (Heroku/Railway)
   - CI/CD avec GitHub Actions

3. **Scaling**
   - Base de donn√©es (PostgreSQL)
   - Cache Redis
   - Queue de traitement (Celery)
