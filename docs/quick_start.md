# ğŸš€ POC Quick Start - Virality Prediction

## ğŸ¯ Objectif

Valider rapidement l'idÃ©e de prÃ©diction de viralitÃ© TikTok en testant le pipeline end-to-end et en crÃ©ant un modÃ¨le baseline.

## âš¡ DÃ©marrage ImmÃ©diat (5 minutes)

### 1. Test Rapide du Pipeline (avec agrÃ©gation automatique)

```bash
# Test avec 2 vidÃ©os seulement (agrÃ©gation automatique incluse)
python3 scripts/test_pipeline_minimal.py
```

**Ce test va :**

- âœ… Scraper 2 vidÃ©os de 1 compte
- âœ… Analyser avec Gemini AI
- âœ… Extraire les features
- âœ… **AgrÃ©ger automatiquement** les donnÃ©es
- âœ… VÃ©rifier que tout fonctionne
- âœ… Tester les endpoints API

### 2. Analyse des DonnÃ©es Existantes

```bash
# Analyser les donnÃ©es existantes sans relancer le pipeline
python3 scripts/analyze_existing_data.py --dataset-dir data/dataset_poc_test --feature-set comprehensive

# Sauvegarder le modÃ¨le entraÃ®nÃ©
python3 scripts/analyze_existing_data.py --dataset-dir data/dataset_poc_test --feature-set comprehensive --save-model

# Analyser avec diffÃ©rents feature sets
python3 scripts/analyze_existing_data.py --dataset-dir data/dataset_poc_test --feature-set metadata
python3 scripts/analyze_existing_data.py --dataset-dir data/dataset_poc_test --feature-set visual_granular
```

**Cette analyse va :**

- ğŸ“Š Analyser la distribution des donnÃ©es
- ğŸ”— Calculer les corrÃ©lations
- ğŸ¤– CrÃ©er un modÃ¨le baseline
- ğŸ’¡ GÃ©nÃ©rer des insights

## ğŸš€ API Usage - Production Ready

### **ğŸ“Š Analysis Endpoints (Post-Publication Data)**

#### Analyze Existing Video

```bash
# Analyser une vidÃ©o existante avec donnÃ©es rÃ©elles
curl -X POST "http://localhost:8000/analyze-tiktok-url" \
  -H "Content-Type: application/json" \
  -d '{
    "url": "https://www.tiktok.com/@swarecito/video/7505706702050823446",
    "use_cache": true
  }'
```

**Use Case**: "Pourquoi cette vidÃ©o a-t-elle Ã©tÃ© virale?"

- âœ… Score de viralitÃ© actuel (0.75 = 75% de potentiel viral)
- âœ… DonnÃ©es d'engagement rÃ©elles (vues, likes, commentaires)
- âœ… Analyse d'importance des features
- âœ… Recommandations spÃ©cifiques d'amÃ©lioration

#### Analyze Profile

```bash
# Analyser plusieurs vidÃ©os d'un profil
curl -X POST "http://localhost:8000/analyze-tiktok-profile" \
  -H "Content-Type: application/json" \
  -d '{
    "username": "swarecito",
    "max_videos": 10,
    "use_cache": true
  }'
```

**Use Case**: "Qu'est-ce qui rend les vidÃ©os de ce crÃ©ateur virales?"

### **ğŸ¯ Simulation Endpoints (Pre-Publication Scenarios)**

#### Simulate Publication Scenarios

```bash
# Simuler diffÃ©rents scÃ©narios de publication
curl -X POST "http://localhost:8000/simulate-virality" \
  -H "Content-Type: application/json" \
  -d '{
    "video_url": "https://www.tiktok.com/@swarecito/video/7505706702050823446",
    "use_cache": true,
    "scenarios": [
      {
        "name": "Publication Matin",
        "description": "Publier Ã  9h le lundi",
        "publication_hour": 9,
        "publication_day": "monday",
        "hashtags": ["fyp", "viral", "trending"],
        "engagement_multiplier": 1.2
      },
      {
        "name": "Publication Soir",
        "description": "Publier Ã  20h le vendredi",
        "publication_hour": 20,
        "publication_day": "friday",
        "hashtags": ["fyp", "comedy", "funny"],
        "engagement_multiplier": 1.5
      }
    ],
    "simulation_count": 5
  }'
```

**Use Case**: "Quand devrais-je publier cette vidÃ©o pour maximiser la viralitÃ©?"

**âš ï¸ Important**: Cette simulation est PRE-PUBLICATION et n'utilise PAS les donnÃ©es d'engagement rÃ©elles. L'URL de la vidÃ©o sert uniquement Ã  l'analyse du contenu (durÃ©e, format, etc.), pas aux vues/likes/commentaires.

- âœ… Meilleur moment de publication recommandÃ©
- âœ… Combinaisons de hashtags optimales
- âœ… AmÃ©lioration de viralitÃ© attendue
- âœ… Suggestions d'optimisation de contenu
- âœ… Support du cache pour l'efficacitÃ©
- âœ… Simulation de scÃ©narios sans biais des donnÃ©es rÃ©elles

## ğŸ”„ Analysis vs Simulation: Quand Utiliser Quoi?

### **ğŸ“Š Utilisez Analysis Endpoints Quand:**

- âœ… Vous avez une vidÃ©o TikTok existante
- âœ… Vous voulez comprendre pourquoi elle a Ã©tÃ© virale (ou pas)
- âœ… Vous voulez analyser des donnÃ©es d'engagement rÃ©elles
- âœ… Vous faites de la recherche concurrentielle

**Exemple**: "Pourquoi la vidÃ©o ChatGPT de @swarecito a-t-elle eu 53k vues?"

### **ğŸ¯ Utilisez Simulation Endpoints Quand:**

- âœ… Vous planifiez de publier une vidÃ©o
- âœ… Vous voulez optimiser le timing de publication
- âœ… Vous voulez tester diffÃ©rentes stratÃ©gies de hashtags
- âœ… Vous voulez prÃ©dire la viralitÃ© avant publication

**Exemple**: "Quand devrais-je publier ma nouvelle vidÃ©o pour maximiser la viralitÃ©?"

## ğŸ“ˆ InterprÃ©tation des Scores

### **Score de ViralitÃ© (0-1)**

- **0.0-0.3**: Potentiel viral faible
- **0.3-0.6**: Potentiel viral modÃ©rÃ©
- **0.6-0.8**: Potentiel viral Ã©levÃ©
- **0.8-1.0**: Potentiel viral trÃ¨s Ã©levÃ©

### **Score de Confiance (0-1)**

- **0.0-0.5**: Confiance faible dans la prÃ©diction
- **0.5-0.8**: Confiance modÃ©rÃ©e
- **0.8-1.0**: Confiance Ã©levÃ©e

### **Score RÂ² (0-1)**

- **0.457**: Notre modÃ¨le explique 45.7% de la variance virale
- **Standard industriel**: 0.4+ est considÃ©rÃ© comme bon pour la prÃ©diction sur rÃ©seaux sociaux

## ğŸ“‹ Plan Complet (3 semaines)

### **Semaine 1 : Validation Rapide**

```bash
# Jour 1-2 : Test pipeline avec agrÃ©gation automatique
python3 scripts/test_pipeline_with_aggregation.py

# Jour 3-4 : Analyse et modÃ¨le baseline
python3 scripts/analyze_existing_data.py --dataset-dir data/dataset_poc_test --feature-set comprehensive --save-model

# Jour 5 : Ã‰valuation et planification
```

### **Semaine 2 : DÃ©veloppement du ModÃ¨le**

```bash
# Jour 1-2 : Dataset d'entraÃ®nement (150 vidÃ©os)
python3 scripts/run_pipeline.py --dataset poc_training --batch-size 3 --videos-per-account 15 --max-total-videos 150 --feature-system modular --feature-set comprehensive

# Jour 3-4 : ModÃ¨le avancÃ©
python3 scripts/train_advanced_model.py --dataset-dir data/dataset_poc_training

# Jour 5 : API de prÃ©diction
python3 scripts/create_prediction_api.py
```

### **Semaine 3 : DÃ©mo et Validation**

```bash
# Jour 1-2 : DÃ©mo Upwork
python3 scripts/generate_virality_report.py --video-urls urls.txt

# Jour 3-4 : IntÃ©gration app mobile
# (Code JavaScript/React Native)

# Jour 5 : Tests et optimisations
```

## ğŸ¯ MÃ©triques de SuccÃ¨s

### **Techniques (Phase 1)**

- âœ… **Pipeline fonctionnel** end-to-end
- âœ… **AgrÃ©gation automatique** des features
- âœ… **RÂ² Score > 0.4** sur validation croisÃ©e
- âœ… **Features extraites** correctement
- âœ… **DonnÃ©es valides** et cohÃ©rentes

### **Business (Phase 3)**

- âœ… **DÃ©mo Upwork** prÃªte
- âœ… **Rapport PDF** professionnel
- âœ… **API fonctionnelle** pour l'app
- âœ… **Insights actionnables** gÃ©nÃ©rÃ©s

## ğŸš¨ DÃ©pannage Rapide

### **Erreur de dÃ©pendances**

```bash
pip install pandas numpy matplotlib scikit-learn seaborn google-generativeai
```

### **Erreur de pipeline**

```bash
# VÃ©rifier les logs
tail -f logs/pipeline_poc_test_aggregation.log

# VÃ©rifier les erreurs
tail -f logs/errors.log
```

### **Erreur d'API Gemini**

```bash
# VÃ©rifier la clÃ© API
echo $GOOGLE_API_KEY

# Tester le service Gemini
python3 scripts/test_gemini.py

# VÃ©rifier l'architecture des services
ls -la src/services/
```

### **Erreur de Features ML**

```bash
# Tester l'API aprÃ¨s correction des features
python3 scripts/test_api_fixed.py

# VÃ©rifier que l'API utilise les bonnes features (16 au lieu de 34)
curl -X POST "http://localhost:8000/analyze-tiktok-url" \
  -H "Content-Type: application/json" \
  -d '{"url": "https://www.tiktok.com/@swarecito/video/7505706702050823446", "use_cache": false}' | jq '.prediction.virality_score'
```

### **Fichier agrÃ©gÃ© manquant**

```bash
# AgrÃ©gation manuelle si nÃ©cessaire
python3 scripts/aggregate_features.py --dataset-dir data/dataset_poc_test --feature-set comprehensive --show-stats

# Ou analyser directement les features existantes
python3 scripts/analyze_existing_data.py --dataset-dir data/dataset_poc_test --feature-set comprehensive
```

## ğŸ“Š Structure des DonnÃ©es

```
data/dataset_poc_test_aggregation/
â”œâ”€â”€ batch_20241201_143022.json    # DonnÃ©es scrapÃ©es
â”œâ”€â”€ gemini_analysis/              # Analyses Gemini
â”‚   â””â”€â”€ @account_name/
â”‚       â””â”€â”€ 20241201/
â”‚           â””â”€â”€ video_*.json
â””â”€â”€ features/                     # Features extraites
    â”œâ”€â”€ @account_name_features_comprehensive.csv  # Par compte
    â””â”€â”€ aggregated_comprehensive.csv              # AgrÃ©gÃ© automatiquement
```

## ğŸ¯ Prochaines Ã‰tapes

### **Si le test rapide rÃ©ussit :**

1. **Augmenter le dataset** Ã  150 vidÃ©os
2. **Optimiser le modÃ¨le** (Gradient Boosting, XGBoost)
3. **CrÃ©er l'API** de prÃ©diction
4. **PrÃ©parer la dÃ©mo** Upwork

### **Si le test Ã©choue :**

1. **Analyser les erreurs** dans les logs
2. **Corriger les problÃ¨mes** identifiÃ©s
3. **Retester** avec moins de vidÃ©os
4. **ConsidÃ©rer un pivot** vers Account Analyzer

## ğŸ’¡ Tips pour le POC

### **Optimisation des CoÃ»ts**

- Commencer avec **6 vidÃ©os** seulement
- Utiliser **batch-size=1** pour Ã©viter les erreurs
- **Tester localement** avant de scaler

### **Optimisation du Temps**

- **AgrÃ©gation automatique** incluse dans le pipeline
- **ParallÃ©liser** les phases quand possible
- **Cacher les rÃ©sultats** pour Ã©viter les re-calculs
- **Logs dÃ©taillÃ©s** pour le debugging

### **QualitÃ© des DonnÃ©es**

- **Valider** chaque phase avant de continuer
- **VÃ©rifier** la cohÃ©rence des features
- **Nettoyer** les donnÃ©es aberrantes

## ğŸ¯ Commandes de Test Rapide

```bash
# Test minimal avec agrÃ©gation automatique (2 minutes)
python3 scripts/test_pipeline_minimal.py

# Test avec analyse des donnÃ©es existantes (2 minutes)
python3 scripts/analyze_existing_data.py --dataset-dir data/dataset_poc_test --feature-set comprehensive

# Test complet (30 minutes)
python3 scripts/run_pipeline.py --dataset poc_validation --batch-size 2 --videos-per-account 10 --max-total-videos 40 --feature-set comprehensive
```

## ğŸ”§ Scripts Disponibles

### **Pipeline et Tests**

- `scripts/test_pipeline_minimal.py` - Test complet avec agrÃ©gation automatique (recommandÃ©)
- `scripts/run_pipeline.py` - Pipeline principal

### **Analyse des DonnÃ©es**

- `scripts/analyze_existing_data.py` - Analyse complÃ¨te avec ML (recommandÃ©)
- `scripts/aggregate_features.py` - AgrÃ©gation manuelle si nÃ©cessaire

### **Services RÃ©utilisables**

- `src/services/gemini_service.py` - Service d'analyse Gemini centralisÃ©
- `src/services/README.md` - Documentation de l'architecture des services

**Note**: Le script d'analyse transforme automatiquement les dates en features numÃ©riques (heure, jour de semaine, etc.) pour optimiser les performances du modÃ¨le.

## ğŸ“š Documentation API

- **Swagger UI**: `http://localhost:8000/docs`
- **ReDoc**: `http://localhost:8000/redoc`
- **README API**: `src/api/README.md`
- **Health Check**: `http://localhost:8000/health`

**PrÃªt Ã  commencer ?** ğŸš€

```bash
# Commencer maintenant
python3 scripts/test_pipeline_minimal.py
```
