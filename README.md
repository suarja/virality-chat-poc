# TikTok Virality Analysis Pipeline

A comprehensive pipeline for analyzing TikTok videos to predict and understand virality factors using batch processing, AI analysis, and robust data validation.

## ğŸš€ Features

### âœ… Batch Processing System

- **Configurable batch sizes** (1-10 accounts per batch)
- **Progress tracking** with automatic resume capability
- **Error handling** with detailed logging and retry mechanisms
- **Dataset versioning** for multiple experiments

### âœ… Data Validation Guards

- **Account validation** (username, video count, data integrity)
- **Video filtering** (minimum views, age limits, sponsored content detection)
- **Quality thresholds** (engagement metrics, duration limits)
- **Analysis validation** (Gemini completeness checks)

### âœ… AI-Powered Analysis

- **Google Gemini integration** for video content analysis
- **Visual element detection** (lighting, composition, movement)
- **Content structure analysis** (narrative flow, engagement factors)
- **Technical quality assessment** (audio, transitions, style)

### âœ… Feature Engineering

- **Engagement metrics** (views, likes, comments, shares)
- **Temporal features** (posting time, day patterns)
- **Content features** (hashtags, descriptions, music)
- **AI-derived features** (visual analysis, content categories)

## ğŸ“‹ Quick Start

### 1. Setup

```bash
# Clone and setup
git clone <repository-url>
cd virality-chat-poc
python scripts/setup_project.py

# Activate environment
source venv/bin/activate  # macOS/Linux
# or
venv\Scripts\activate     # Windows

# Configure API keys
cp .env.example .env
# Edit .env with your API keys
```

### 2. Test Installation

```bash
# Test batch processing system
python scripts/test_batch_system.py

# Test data validation
python scripts/test_data_validation.py

# Validate setup
python scripts/validate_setup.py
```

### 3. Run Pipeline

```bash
# Basic run (5 accounts per batch, 15 videos per account)
python scripts/run_pipeline.py --dataset v1

# Custom configuration
python scripts/run_pipeline.py \
    --dataset v1 \
    --batch-size 3 \
    --videos-per-account 10 \
    --max-total-videos 300

# Test run
python scripts/run_pipeline.py \
    --dataset test \
    --batch-size 1 \
    --videos-per-account 2
```

## ğŸ—ï¸ Architecture

```
Pipeline Flow:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Batch Input   â”‚â”€â”€â”€â–¶â”‚  Phase 1:       â”‚â”€â”€â”€â–¶â”‚  Phase 2:       â”‚
â”‚   (N accounts)  â”‚    â”‚  Scraping +     â”‚    â”‚  Gemini         â”‚
â”‚                 â”‚    â”‚  Validation     â”‚    â”‚  Analysis       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚                       â”‚
                                â–¼                       â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚  Save Raw Data  â”‚    â”‚  Save Analysis  â”‚
                       â”‚  + Track        â”‚    â”‚  + Validate     â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                        â”‚
                                                        â–¼
                                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                               â”‚  Phase 3:       â”‚
                                               â”‚  Features       â”‚
                                               â”‚  Extraction     â”‚
                                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                        â”‚
                                                        â–¼
                                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                               â”‚  Mark Complete  â”‚
                                               â”‚  Update source  â”‚
                                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“Š Data Quality Controls

### Validation Rules

- **Minimum views**: 1,000 per video
- **Maximum age**: 6 months
- **Duration limits**: 1-600 seconds
- **Content filtering**: No sponsored content
- **Required fields**: All metadata present
- **Analysis quality**: Complete Gemini analysis

### Error Handling

- **Automatic retry**: Failed accounts retry mechanism
- **Progress preservation**: Resume from where it left off
- **Detailed logging**: Complete error tracking
- **Quality assurance**: Data validation at each step

## ğŸ“ Directory Structure

```
.
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ scraping/
â”‚   â”‚   â””â”€â”€ tiktok_scraper.py      # TikTok data collection
â”‚   â”œâ”€â”€ features/
â”‚   â”‚   â””â”€â”€ data_processor.py      # Feature extraction
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ batch_tracker.py       # Progress tracking
â”‚       â””â”€â”€ data_validator.py      # Data validation
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ run_pipeline.py            # Main pipeline
â”‚   â”œâ”€â”€ test_batch_system.py       # Batch tests
â”‚   â””â”€â”€ test_data_validation.py    # Validation tests
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ dataset_v1/
â”‚   â”‚   â”œâ”€â”€ source.txt             # Processed accounts
â”‚   â”‚   â”œâ”€â”€ errors.txt             # Error tracking
â”‚   â”‚   â””â”€â”€ metadata.json          # Dataset info
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ dataset_v1/
â”‚   â”‚       â””â”€â”€ batch_*.json       # Raw video data
â”‚   â”œâ”€â”€ analysis/
â”‚   â”‚   â””â”€â”€ dataset_v1/
â”‚   â”‚       â””â”€â”€ gemini_*.json      # AI analysis
â”‚   â””â”€â”€ features/
â”‚       â””â”€â”€ dataset_v1/
â”‚           â””â”€â”€ features.csv       # Final dataset
â”œâ”€â”€ logs/
â”‚   â”œâ”€â”€ pipeline_*.log             # Pipeline logs
â”‚   â””â”€â”€ errors.log                 # Error logs
â””â”€â”€ docs/
    â”œâ”€â”€ getting_started.md         # Setup guide
    â”œâ”€â”€ pipeline.md                # Technical docs
    â””â”€â”€ features_tracking.md       # Feature status
```

## ğŸ”§ Configuration

### Environment Variables

```bash
# Required
APIFY_API_TOKEN=your_apify_token
GOOGLE_API_KEY=your_gemini_key

# Optional
DEBUG=True
LOG_LEVEL=INFO
```

### Settings (`config/settings.py`)

```python
# Account configuration
TIKTOK_ACCOUNTS = ["@account1", "@account2", ...]

# Processing limits
MAX_VIDEOS_PER_ACCOUNT = 15
MIN_VIEWS_THRESHOLD = 1000

# Quality thresholds
VIRALITY_THRESHOLDS = {
    'low': 10000,
    'medium': 100000,
    'high': 1000000,
}
```

## ğŸ“ˆ Monitoring

### Progress Tracking

```bash
# Check processing status
cat data/dataset_v1/source.txt

# Monitor errors
cat data/dataset_v1/errors.txt

# View logs
tail -f logs/pipeline_v1.log
```

### Quality Metrics

```bash
# Dataset quality report
python scripts/validate_dataset.py --dataset v1

# Feature completeness check
python scripts/check_features.py --dataset v1
```

## ğŸ§ª Testing

### Unit Tests

```bash
# Test batch processing
python scripts/test_batch_system.py

# Test data validation
python scripts/test_data_validation.py

# Test scraping
python scripts/test_scraping.py

# Test Gemini analysis
python scripts/test_gemini.py
```

### Integration Tests

```bash
# Full pipeline test
python scripts/run_pipeline.py --dataset test --batch-size 1

# Error recovery test
python scripts/run_pipeline.py --dataset v1 --retry-failed
```

## ğŸš¨ Troubleshooting

### Common Issues

1. **API Rate Limits**: Automatic retry with exponential backoff
2. **Network Errors**: Logged and retried automatically
3. **Data Corruption**: Filtered out by validation guards
4. **Memory Issues**: Batch processing prevents memory overflow

### Debug Commands

```bash
# Check API keys
python scripts/validate_setup.py

# Test individual components
python scripts/test_scraping.py
python scripts/test_gemini.py

# Validate data quality
python scripts/test_data_validation.py
```

## ğŸ“š Documentation

- **[Getting Started](docs/getting_started.md)**: Setup and first run
- **[Pipeline Guide](docs/pipeline.md)**: Technical implementation
- **[Features Tracking](docs/features_tracking.md)**: Development status
- **[Research Synthesis](docs/articles/research_synthesis.md)**: Academic foundation

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch: `git checkout -b feature/new-feature`
3. Make changes and test thoroughly
4. Update documentation
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- Research based on academic papers in `docs/articles/`
- Powered by Google Gemini AI
- Data collection via Apify API
